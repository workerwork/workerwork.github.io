<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>linux on WorkSpace</title>
    <link>https://workerwork.github.io/categories/linux/</link>
    <description>Recent content in linux on WorkSpace</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 11 Jan 2021 09:49:51 +0800</lastBuildDate>
    
	<atom:link href="https://workerwork.github.io/categories/linux/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>linux checksum</title>
      <link>https://workerwork.github.io/posts/checksum/</link>
      <pubDate>Mon, 11 Jan 2021 09:49:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/checksum/</guid>
      <description>1. 关键结构 由于目前很多网卡设备是支持对L4层数据包进行校验和的计算和验证的，所以在L4协议软件的实现中，
会根据网卡的支持情况作不同的处理，为此内核在struct sk_buff结构和struct net_device中增加了校验和相关的参数，如下：
struct sk_buff
上面的结构中，和校验和有关的几个字段如下：
#define CHECKSUM_NONE 0 #define CHECKSUM_UNNECESSARY 1 #define CHECKSUM_COMPLETE 2 #define CHECKSUM_PARTIAL 3 struct sk_buff { union { __wsum	csum; struct { __u16	csum_start; __u16	csum_offset; }; }; __u8 ip_summed:2, }  联合体中哪个成员有效取决于ip_summed的值，ip_summed共两个bit，可取四个标志，而且在发送和接收时的含义还有所不同
在接收过程中，ip_summed字段包含了设备驱动告诉L4软件当前校验和的状态，各取值含义如下：
 CHECKSUM_NONE：硬件没有提供校验和，可能是硬件不支持，也可能是硬件校验出错但是并未丢弃数据包，而是让L4软件重新校验 CHECKSUM_UNNECESSARY：硬件已经进行了完整的校验，无需软件再进行检查，L4收到数据包后如果检查ip_summed是这种情况，就可以跳过校验过程 CHECKSUM_COMPLETE：硬件已经校验了L4报头和其payload部分，并且校验和保存在了csum中，L4软件只需要再计算伪报头然后检查校验结果即可  在发送过程中，ip_summed字段包含了L4软件告诉设备驱动程序当前校验和的状态，各取值含义如下：
 CHECKSUM_NONE：L4软件已经进行了校验，硬件无需做任何事情 CHECKSUM_PARTIAL：L4软件计算了伪报头，并且将值保存在了首部的check字段中，硬件需要计算其余部分的校验和  struct net_device
net_device结构中的feature字段中定义了如下和校验和相关的字段，这些字段表明了硬件计算校验和的能力
NETIF_F_NO_CSUM：该设备非常可靠，无需L4执行任何校验，环回设备一般设置该标记 NETIF_F_IP_CSUM：设备可以对基于IPv4的TCP和UDP数据包进行校验 NETIF_F_IPV6_CSUM：设备可以对基于IPv6的TCP和UDP数据包进行校验 NETIF_F_HW_CSUM： 设备可以对任何L4协议的数据包进行校验
注：这些概念和字段的含义同样适用于TCP校验和处理过程
2. 输入数据报的校验和计算 udp4_csum_init()
@skb: 待校验的数据报 @uh：该数据报的UDP首部 @proto：L4协议号，为IPPROTO_UDP或者IPPROTO_UDPLITE static inline int udp4_csum_init(struct sk_buff *skb, struct udphdr *uh, int proto) { const struct iphdr *iph; int err; //这两个字段用于指示对报文的哪些部分进行校验，cov指coverage， //只有UDPLite使用，对于UDP，会对整个报文进行校验 UDP_SKB_CB(skb)-&amp;gt;partial_cov = 0; UDP_SKB_CB(skb)-&amp;gt;cscov = skb-&amp;gt;len; //UDPLITE，忽略 if (proto == IPPROTO_UDPLITE) { err = udplite_checksum_init(skb, uh); if (err) return err; } iph = ip_hdr(skb); //UDP首部校验和字段为0，这种情况说明已经处理过了，设置为CHECKSUM_UNNECESSARY，后续无需再进行处理 if (uh-&amp;gt;check == 0) { skb-&amp;gt;ip_summed = CHECKSUM_UNNECESSARY; } else if (skb-&amp;gt;ip_summed == CHECKSUM_COMPLETE) { //还有伪首部需要校验，所以添加伪首部校验，如果校验成功，设置为CHECKSUM_UNNECESSARY //csum_tcpudp_magic()计算伪首部校验和后进行验证，如果验证ok，返回0，该函数体系结构相关， //为了高效，用汇编语言实现 if (!</description>
    </item>
    
    <item>
      <title>二进制瘦身</title>
      <link>https://workerwork.github.io/posts/sub-bin/</link>
      <pubDate>Thu, 07 Jan 2021 11:06:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/sub-bin/</guid>
      <description>1. 符号表信息和调试信息 符号表信息（symbols）和调试信息（debug info）是由不同段区分的。
使用 readelf -S binfile 可以查看ELF文件的所有段。
调试信息相关的段：
# readelf -S a.out | grep debug [27] .debug_aranges PROGBITS 0000000000000000 000016d0 [28] .debug_info PROGBITS 0000000000000000 00001700 [29] .debug_abbrev PROGBITS 0000000000000000 00001a0f [30] .debug_line PROGBITS 0000000000000000 00001adb [31] .debug_str PROGBITS 0000000000000000 00001bd2  符号表相关的段：
# readelf -S a.out | grep tab [32] .symtab SYMTAB 0000000000000000 00001e18 [33] .strtab STRTAB 0000000000000000 00002670 [34] .shstrtab STRTAB 0000000000000000 00002a8f  注： 下文中提及的符号表相关段将不包括 .</description>
    </item>
    
    <item>
      <title>EXPORT SYMBOL</title>
      <link>https://workerwork.github.io/posts/export-symbol/</link>
      <pubDate>Wed, 30 Dec 2020 15:05:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/export-symbol/</guid>
      <description>1. 背景 EXPORT_SYMBOL只出现在2.6内核中，在2.4内核默认的非static 函数和变量都会自动导入到kernel 空间的， 都不用EXPORT_SYMBOL() 做标记的。2.6就必须用EXPORT_SYMBOL() 来导出来（因为2.6默认不导出所有的符号）
2. EXPORT_SYMBOL的作用 EXPORT_SYMBOL标签内定义的函数或者符号对全部内核代码公开， 不用修改内核代码就可以在您的内核模块中直接调用，即使用EXPORT_SYMBOL可以将一个函数以符号的方式导出给其他模块使用
EXPORT_SYMBOL(符号名); 可以导出static函数到符号表中 EXPORT_SYMBOL_GPL(符号名) //用于GPL协议认证的模块 EXPORT_SYMBOL_GPL的符号必须要用MODULE_LICENSE(&amp;quot;GPL&amp;quot;)或者用MODULE_LICENSE(&amp;quot;Dual BSD/GPL&amp;quot;)之后才能在模块中引用。 而且MODULE_LICENSE(&amp;quot;char&amp;quot;)中的char不可以是任意字符，否则错误和没有MODULE_LICENSE效果一样。  这里要和System.map做一下对比： System.map 中的是连接时的函数地址。连接完成以后，在2.6内核运行过程中，是不知道哪个符号在哪个地址的。 EXPORT_SYMBOL 的符号，是把这些符号和对应的地址保存起来，在内核运行的过程中，可以找到这些符号对应的地址。 而模块在加载过程中，其本质就是能动态连接到内核，如果在模块中引用了内核或其它模块的符号， 就要EXPORT_SYMBOL这些符号，这样才能找到对应的地址连接
3. 使用方法  在模块函数定义之后使用EXPORT_SYMBOL（函数名） 在掉用该函数的模块中使用extern对之声明 首先加载定义该函数的模块，再加载调用该函数的模块  另外，在编译调用某导出函数的模块时，往往会有WARNING: &amp;ldquo;＊＊＊＊&amp;rdquo; [＊＊＊＊＊＊＊＊＊＊] undefined! 使用dmesg命令后会看到相同的信息。开始我以为只要有这个错误就不能加载模块，后来上网查了一下， 发现这主要是因为在编译连接的时候还没有和内核打交道，当然找不到symbol了，但是由于你生成的是一个内核模块， 所以LD不提示error，而是给出一个warning，寄希望于在insmod的时候，内核能够把这个symbol连接上
1.EXPORT_SYMBOL EXPORT_SYMBOL( my_pub_func); 在预编译阶段会解析为: extern void *__crc_my_pub_func __attribute__((weak)); static const unsigned long __kcrctab_my_pub_func __attribute__((__used__)) __attribute__((section(&amp;quot;__kcrctab&amp;quot; &amp;quot;&amp;quot;), unused)) = (unsigned long) &amp;amp;__crc_my_pub_func; static const char __kstrtab_my_pub_func[] __attribute__((section(&amp;quot;__ksymtab_strings&amp;quot;))) = &amp;quot;&amp;quot; &amp;quot;my_pub_func&amp;quot;; static const struct kernel_symbol __ksymtab_my_pub_func __attribute__((__used__)) __attribute__((section(&amp;quot;__ksymtab&amp;quot; &amp;quot;&amp;quot;), unused)) = { (unsigned long)&amp;amp;my_pub_func, __kstrtab_my_pub_func }; 很显然__ksymtab_my_pub_func存储了my_pub_func的地址和符号信息,该符号对应的地址 只有insmod后才会确定; __ksymtab_my_pub_func会链接到__ksymtab section,__ksymtab section中的所有内容就构成了 内核&amp;quot;导出&amp;quot;的符号表,这个表在insmod 时候会用到.</description>
    </item>
    
    <item>
      <title>xfrm框架</title>
      <link>https://workerwork.github.io/posts/xfrm/</link>
      <pubDate>Mon, 28 Dec 2020 15:20:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/xfrm/</guid>
      <description>1. 简介 IPsec协议帮助IP层建立安全可信的数据包传输通道。
当前已经有了如StrongSwan、OpenSwan等比较成熟的解决方案，而它们都使用了Linux内核中的XFRM框架进行报文接收发送.
XFRM的正确读音是transform(转换), 这表示内核协议栈收到的IPsec报文需要经过转换才能还原为原始报文；
同样地，要发送的原始报文也需要转换为IPsec报文才能发送出去.
2. XFRM实例 IPsec中有两个重要概念：
安全关联(Security Association)和安全策略(Security Policy)，这两类信息都需要存放在内核XFRM。
核XFRM使用netns_xfrm这个结构来组织这些信息，它也被称为xfrm instance(实例)。
从它的名字也可以看出来，这个实例是与network namespace相关的，每个命名空间都有这样的一个实例，实例间彼此独立。
所以同一台主机上的不同容器可以互不干扰地使用XFRM
struct net { ...... #ifdef CONFIG_XFRM struct netns_xfrm	xfrm; #endif ...... }  3. Netlink通道 上面提到了Security Association和Security Policy信息，这些信息一般是由用户态IPsec进程(eg. StrongSwan)
下发到内核XFRM的，这个下发的通道在network namespace初始化时创建。
static int __net_init xfrm_user_net_init(struct net *net) { struct sock *nlsk; struct netlink_kernel_cfg cfg = { .groups	= XFRMNLGRP_MAX, .input	= xfrm_netlink_rcv, }; nlsk = netlink_kernel_create(net, NETLINK_XFRM, &amp;amp;cfg); ...... return 0; }  这样，当用户下发IPsec配置时，内核便可以调用 xfrm_netlink_rcv() 来接收.</description>
    </item>
    
    <item>
      <title>oom killer</title>
      <link>https://workerwork.github.io/posts/oom-killer/</link>
      <pubDate>Mon, 28 Dec 2020 11:20:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/oom-killer/</guid>
      <description>1. redis报错 MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error.  redis数据不能写入磁盘了 修正方式：
1.改redis-conf配置文件中的 stop-writes-on-bgsave-error 为 no,保证redis正常运行 2.修改/etc/sysctl.conf 中vm.overcommit_memory 的值为 1，再使用sysctl -p使修改生效，然后重启redis overcommit_memory=0， 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。 overcommit_memory=1， 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。 overcommit_memory=2， 表示内核允许分配超过所有物理内存和交换空间总和的内存 3.查看磁盘占用情况，检查磁盘是否写满 4.查看内存占用，检查是否配额充足,有可能进程被oom-killer干掉了  2. oom-killer Linux 内核有个机制叫OOM killer(Out Of Memory killer)，该机制会监控那些占用内存过大， 尤其是瞬间占用内存很快的进程，然后防止内存耗尽而自动把该进程杀掉。 内核检测到系统内存不足、挑选并杀掉某个进程的过程可以参考内核源代码linux/mm/oom_kill.c， 当系统内存不足的时候，out_of_memory()被触发，然后调用select_bad_process()选择一个”bad”进程杀掉。 如何判断和选择一个”bad进程呢？linux选择”bad”进程是通过调用oom_badness()， 挑选的算法和想法都很简单很朴实：最bad的那个进程就是那个最占用内存的进程。  如何查看</description>
    </item>
    
    <item>
      <title>linux gcc编译</title>
      <link>https://workerwork.github.io/posts/gcc/</link>
      <pubDate>Fri, 25 Dec 2020 14:27:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/gcc/</guid>
      <description>1. 常用编译命令选项 假设源程序文件名为test.c 1. 无选项编译链接 用法：#gcc test.c 作用：将test.c预处理、汇编、编译并链接形成可执行文件。这里未指定输出文件，默认输出为a.out。 2. 选项 -o 用法：#gcc test.c -o test 作用：将test.c预处理、汇编、编译并链接形成可执行文件test。-o选项用来指定输出文件的文件名。 3. 选项 -E 用法：#gcc -E test.c -o test.i 作用：将test.c预处理输出test.i文件。 4. 选项 -S 用法：#gcc -S test.i 作用：将预处理输出文件test.i汇编成test.s文件。 5. 选项 -c 用法：#gcc -c test.s 作用：将汇编输出文件test.s编译输出test.o文件。 6. 无选项链接 用法：#gcc test.o -o test 作用：将编译输出文件test.o链接成最终可执行文件test。 7. 选项-O 用法：#gcc -O1 test.c -o test 作用：使用编译优化级别1编译程序。级别为1~3，级别越大优化效果越好，但编译时间越长。  2. 多源文件的编译方法 如果有多个源文件，基本上有两种编译方法： [假设有两个源文件为test.c和testfun.c] 1. 多个文件一起编译 用法：#gcc testfun.c test.c -o test 作用：将testfun.c和test.c分别编译后链接成test可执行文件。 2. 分别编译各个源文件，之后对编译后输出的目标文件链接。 用法： #gcc -c testfun.</description>
    </item>
    
    <item>
      <title>linux coredump设置</title>
      <link>https://workerwork.github.io/posts/core/</link>
      <pubDate>Thu, 17 Dec 2020 10:27:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/core/</guid>
      <description>1. core 在Linux下程序不寻常退出时，内核会在当前工作目录下生成一个core文件（是一个内存映像，同时加上调试信息，编译时需要加上 -g -Wall）。 使用gdb来查看core文件，可以指示出导致程序出错的代码所在文件和行数。  2. core文件的生成开关和大小限制 1.1 使用ulimit -c命令可查看core文件的生成开关 若结果为0，则表示关闭了此功能，不会生成core文件  1.2 使用ulimit -c filesize命令，可以限制core文件的大小（filesize的单位为kbyte） 如果生成的信息超过此大小，将会被裁剪，最终生成一个不完整的core文件或者根本就不生成。 如果生成被裁减的core文件，调试此core文件的时候，gdb也会提示错误。 用以下命令来表示core文件的大小不受限制. $ ulimit -c unlimited 用以下命令来阻止系统生成core文件: $ ulimit -c 0 备注:ulimit命令设置后只对一个终端有效，所以另起终端后需要重新设置。  3. 设置 Core Dump 的核心转储文件目录和命名规则 2.1 /proc/sys/kernel/core_uses_pid 可以控制产生的 core 文件的文件名中是否添加 pid 作为扩展 ， 文件内容为1，表示添加pid作为扩展名，生成的core文件格式为core.xxxx；为0则表示生成的core文件同一命名为core。 $ echo &amp;quot;1&amp;quot; &amp;gt; /proc/sys/kernel/core_uses_pid  2.2 /proc/sys/kernel/core_pattern 可以设置格式化的 core 文件保存位置或文件名 $ echo &amp;quot;/corefile/core-%e-%p-%t&amp;quot; &amp;gt; /proc/sys/kernel/core_pattern 说明:将会控制所产生的 core 文件会存放到 /corefile 目录下，产生的文件名为 core- 命令名 -pid- 时间戳 以下是参数列表: %p - insert pid into filename 添加pid %u - insert current uid into filename 添加当前uid %g - insert current gid into filename 添加当前gid %s - insert signal that caused the coredump into the filename 添加导致产生core的信号 %t - insert UNIX time that the coredump occurred into filename 添加core文件生成时的unix时间 %h - insert hostname where the coredump happened into filename 添加主机名 %e - insert coredumping executable name into filename 添加命令名  2.</description>
    </item>
    
    <item>
      <title>网卡offload GSO</title>
      <link>https://workerwork.github.io/posts/gso/</link>
      <pubDate>Mon, 30 Nov 2020 17:03:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/gso/</guid>
      <description> 1. GSO和TSO TSO(TCP Segmentation Offload): 是一种利用网卡来对大数据包进行自动分段，降低CPU负载的技术。 其主要是延迟分段
GSO(Generic Segmentation Offload): GSO是协议栈是否推迟分段，在发送到网卡之前判断网卡是否支持TSO，如果网卡支持TSO则让网卡分段，否则协议栈分完段再交给驱动
如果TSO开启，GSO会自动开启
驱动程序在注册网卡设备的时候默认开启GSO: NETIF_F_GSO
驱动程序会根据网卡硬件是否支持来设置TSO: NETIF_F_TSO
可以通过ethtool -K来开关GSO/TSO
2. 开启关系 GSO开启， TSO开启: 协议栈推迟分段，并直接传递大数据包到网卡，让网卡自动分段 GSO开启， TSO关闭: 协议栈推迟分段，在最后发送到网卡前才执行分段 GSO关闭， TSO开启: 同GSO开启， TSO开启 GSO关闭， TSO关闭: 不推迟分段，在tcp_sendmsg中直接发送MSS大小的数据包  对紧急数据包或GSO/TSO都不开启的情况，才不会推迟发送， 默认使用当前MSS
开启GSO后，tcp_send_mss返回mss和单个skb的GSO大小，为mss的整数倍
3. 包处理流程图 </description>
    </item>
    
    <item>
      <title>Linux 内核符号表</title>
      <link>https://workerwork.github.io/posts/system-map/</link>
      <pubDate>Mon, 30 Nov 2020 12:09:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/system-map/</guid>
      <description>1. 什么是符号(symbols) 什么是Symbol?
其实就是kernel中的变量(VariableName)或函数名称(Function Name)
这样可以方便程序员在写程序时可以直接参照这一份Symbol的索引文件，找到所需要的kernel信息，
这一份Symbol的索引文件又称为kernel symbol table
2. 内核符号表(Kernel Symbol Table) 内核符号表，就是在内核的内部函数或变量中，可供外部引用的函数和变量的符号表.
其实就是一个索引文件，它存在的目的就是让外部软件可以知道kernel文件内部实际分配的位置.
编译内核时，System.map文件用于存放内核符号表信息
System.map文件位于/或者/boot、/usr/src/linux/下
3. kallsyms 内核启动时候创建,供oops时定位错误，文件大小总为0，包含当前内核导出的、可供使用的变量或者函数；它只是内核数据的简单表示形式.
/proc/kallsyms是一个在启动时由Linux kernel实时产生的文件，当系统有任何变更时，它就会马上做出修正
可以理解为动态的符号表
4. 符号类型    符号类型 名称 说明     A Absolute 符号的值是绝对值，并且在进一步链接过程中不会被改变   B BSS 符号在未初始化数据区或区（section）中，即在BSS段中   C Common 符号是公共的。公共符号是未初始化的数据。在链接时，多个公共符号可能具有同一名称。如果该符号定义在其他地方，则公共符号被看作是未定义的引用   D Data 符号在已初始化数据区中   G Global 符号是在小对象已初始化数据区中的符号。某些目标文件的格式允许对小数据对象（例如一个全局整型变量）可进行更有效的访问   I Inderect 符号是对另一个符号的间接引用   N Debugging 符号是一个调试符号   R Read only 符号在一个只读数据区中   S Small 符号是小对象未初始化数据区中的符号   T Text 符号是代码区中的符号   U Undefined 符号是外部的，并且其值为0（未定义   - Stabs 符号是a.</description>
    </item>
    
    <item>
      <title>video server</title>
      <link>https://workerwork.github.io/posts/video-server/</link>
      <pubDate>Wed, 19 Aug 2020 13:13:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/video-server/</guid>
      <description>1. SRS介绍 SRS/3.0，OuXuli，是一个流媒体集群，支持RTMP/HLS/WebRTC/SRT/GB28181，高效、稳定、易用，简单而快乐。 101 SRS is a RTMP/HLS/WebRTC/SRT/GB28181 streaming cluster, high efficiency, stable and simple.
项目地址: https://github.com/ossrs/srs
2. 运行docker容器启动srs服务 sudo docker run -d -p 1935:1935 -p 1985:1985 -p 8080:8080 ossrs/srs:3  3. 使用ffmpeg推流 需要安装ffmpeg
./pushflow.sh cat pushflow.sh #!/bin/bash while : do sudo ffmpeg -re -i dog.mp4 -vcodec copy -acodec copy -f flv -y rtmp://192.168.1.7:1935/live/livestream sleep 1 done  4. 终端使用vlc播放器拉流 视频地址填写: rtmp://192.168.1.7:1935/live/livestream
5. 使用live555支持rtsp 需要添加网关以指定监听地址 可以使用ffmpeg来转换视频源格式
ffmpeg -i dance.mp4 -codec copy -bsf: h264_mp4toannexb -f h264 dance.</description>
    </item>
    
    <item>
      <title>openssh8.1 rpm build</title>
      <link>https://workerwork.github.io/posts/openssh/</link>
      <pubDate>Fri, 14 Aug 2020 15:36:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/openssh/</guid>
      <description>1. 创建工作路径 mkdir -p /root/rpmbuild/{SOURCES,SPECS} cp openssh-8.1p1.tar.gz /root/rpmbuild/SOURCES/  2. 下载源码包 wget https://openbsd.hk/pub/OpenBSD/OpenSSH/portable/openssh-8.1p1.tar.gz  3. 制作准备 yum install rpm-build zlib-devel openssl-devel gcc perl-devel pam-devel unzip tar -zxf openssh-8.1p1.tar.gz cp ./openssh-8.1p1/contrib/redhat/openssh.spec . sed -i -e &amp;quot;s/%define no_x11_askpass 0/%define no_x11_askpass 1/g&amp;quot; openssh.spec sed -i -e &amp;quot;s/%define no_gnome_askpass 0/%define no_gnome_askpass 1/g&amp;quot; openssh.spec  4. 制作rpm包 rpmbuild -ba openssh.spec 如果出现 错误：构建依赖失败： openssl-devel &amp;lt; 1.1 被 ?? 需要 解决方法： vi openssh.spec 注释掉 BuildRequires: openssl-devel &amp;lt; 1.</description>
    </item>
    
    <item>
      <title>自建kvm虚拟机</title>
      <link>https://workerwork.github.io/posts/kvm2/</link>
      <pubDate>Wed, 22 Jul 2020 10:35:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/kvm2/</guid>
      <description>1. 自定义虚拟机 egrep -q &amp;quot;(svm|vmx)&amp;quot; /proc/cpuinfo &amp;amp;&amp;amp; echo &amp;quot;yes&amp;quot; lsmod|grep kvm # centos yum install -y qemu-kvm #KVM主程序，KVM虚拟化模块 yum install -y libvirt #虚拟化服务库 yum install -y bridge-utils ln -s /usr/libexec/qemu-kvm /usr/bin/qemu-kvm # ubuntu apt install qemu qemu-kvm apt install libvirt-bin apt install bridge-utils ln -s /usr/bin/qemu-system-x86_64 /usr/bin/qemu-kvm systemctl start libvirtd systemctl enable libvirtd qemu-img create -f qcow2 vm_NGC.img 20G #创建磁盘镜像 qemu-kvm -name vm_NGC -m 4096 -cpu host -enable-kvm -smp 8 -hda vm_NGC.</description>
    </item>
    
    <item>
      <title>keepalived应用</title>
      <link>https://workerwork.github.io/posts/keepalived/</link>
      <pubDate>Tue, 30 Jun 2020 14:23:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/keepalived/</guid>
      <description>1. 监控脚本 在Master节点和Slave节点 /etc/keepalived目录下添加check_nginx.sh 文件，用于检测Nginx的存活状况
#!/bin/bash #时间变量，用于记录日志 d=`date --date today +%Y%m%d_%H:%M:%S` #计算nginx进程数量 n=`ps -C nginx --no-heading|wc -l` #如果进程为0，则尝试启动nginx，并且再次检测nginx进程数量， #如果还为0，说明nginx无法启动，此时需要关闭keepalived if [ $n -eq &amp;quot;0&amp;quot; ]; then #如果挂掉了，就启动nginx #注意nginx.conf配置文件的位置 #尝试重新启动nginx /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf sleep 3 #睡眠3秒 n2=`ps -C nginx --no-heading|wc -l` if [ $n2 -eq &amp;quot;0&amp;quot; ]; then #把nginx宕机时间写入日志 echo &amp;quot;$d nginx down,keepalived will stop&amp;quot; &amp;gt;&amp;gt; /usr/local/nginx/logs/check_ng.log #启动失败，将keepalived服务杀死。将vip漂移到其它备份节点 service keepalived stop fi fi  授权: chmod 755 /etc/keepalived/check_nginx.sh
2. 非抢占模式 在Master 节点 /etc/keepalived目录下，配置keepalived.</description>
    </item>
    
    <item>
      <title>网卡命名</title>
      <link>https://workerwork.github.io/posts/eth-name/</link>
      <pubDate>Tue, 30 Jun 2020 10:25:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/eth-name/</guid>
      <description>1. 背景 服务器通常有多块网卡，有板载集成的，同时也有插在PCIe插槽的.
Linux系统的命名原来是eth0,eth1这样的形式，但是这个编号往往不一定准确对应网卡接口的物理顺序.
为解决这类问题，dell开发了biosdevname方案.
systemd v197版本中将dell的方案作了进一步的一般化拓展.
linux内核启动过程中，会默认给网卡以ethX方式随机命名，然后再通过systemd去rename成其他名称.
2. rename流程 step1 依据/usr/lib/udev/rules.d/60-net.rules， 查看是否有ifcfg-xx配置文件（路径在/etc/sysconfig/network-scripts/), 是否有定义了指定MAC地址的配置文件（ifcfg-xx ，xx必须和配置文件的内容DEVICE一致），如果有，则命名改网卡； step2 依据/usr/lib/udev/rules.d/71-biosdevname.rules，如果biosdevname使能了（安装了biosdevname这个包，且内核启动参数显式设置为1）， 且网卡没有在step1中定义，则按照biosdevname命名规则rename网卡；（注意，如果没有安装biosdevname这个包，就没有这个文件） step3, 依据/lib/udev/rules.d/75-net-description.rules，将udev工具会根据device属性将填写网卡的属性命名，可能一个网卡会有多个维度的名称; step4，udev 根据step3中的赋值，按照指定的scheme规则，去给在step1 step2中没有命名的网卡命名; 强调：这个step顺序是在我们没有自定义自己的rules的前提下，如果用户自定义了自己的rules，则用户自定义为优先级最高  3. 命令策略(scheme规则) 1.如果从BIOS中能够取到可用的，板载网卡的索引号，则使用这个索引号命名，例如: eno1，如不能则尝试2 2.如果从BIOS中能够取到可以用的，网卡所在的PCI-E热插拔插槽(注：pci槽位号)的索引号，则使用这个索引号命名，例如: ens1，如不能则尝试3 3.如果能拿到设备所连接的物理位置（PCI总线号+槽位号？）信息，则使用这个信息命名，例如:enp2s0，如不能则尝试4 4.传统的kernel命名方法，例如: eth0，这种命名方法的结果不可预知的，即可能第二块网卡对应eth0，第一块网卡对应eth1 5.使用网卡的MAC地址来命名，这个方法一般不使用 同一个网卡通常同时具有多个维度的名称，systemd在选取的时候，按照有先后次序，使用先命中的 顺序可以简单理解为(eno1-ens1-enp1) root@Bai5gc:/sys/class/net/eth1# udevadm info /sys/class/net/eth1 P: /devices/pci0000:00/0000:00:02.2/0000:03:00.0/net/eth1 E: DEVPATH=/devices/pci0000:00/0000:00:02.2/0000:03:00.0/net/eth1 E: ID_BUS=pci E: ID_MODEL_FROM_DATABASE=Ethernet Connection X552 10 GbE Backplane E: ID_MODEL_ID=0x15ab E: ID_NET_DRIVER=ixgbe E: ID_NET_LINK_FILE=/lib/systemd/network/99-default.link E: ID_NET_NAME_MAC=enxb4a9fca897e7 E: ID_NET_NAME_ONBOARD=eno3 E: ID_NET_NAME_PATH=enp3s0f0 E: ID_PATH=pci-0000:03:00.0 E: ID_PATH_TAG=pci-0000_03_00_0 E: ID_PCI_CLASS_FROM_DATABASE=Network controller E: ID_PCI_SUBCLASS_FROM_DATABASE=Ethernet controller E: ID_VENDOR_FROM_DATABASE=Intel Corporation E: ID_VENDOR_ID=0x8086 E: IFINDEX=3 E: INTERFACE=eth1 E: SUBSYSTEM=net E: SYSTEMD_ALIAS=/sys/subsystem/net/devices/eth1 E: TAGS=:systemd: E: USEC_INITIALIZED=5061037 E: net.</description>
    </item>
    
    <item>
      <title>搭建本地apt仓库</title>
      <link>https://workerwork.github.io/posts/local-apt/</link>
      <pubDate>Mon, 25 May 2020 14:34:21 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/local-apt/</guid>
      <description>1. 安装工具 #apt-get install dpkg-dev #这个比较全 apt-get install gnupg apt-get install rng-tools  2. 搜集软件和依赖 # 查询依赖关系 root@localhost:~/df/packages# apt-cache depends nginx nginx |Depends: nginx-core |Depends: nginx-full |Depends: nginx-light Depends: nginx-extras |Depends: nginx-core |Depends: nginx-full |Depends: nginx-light Depends: nginx-extras # 下载 sudo rm -rf /var/cache/apt/archives/* # 清空缓存目录，这一步也可以不做 sudo apt-get -d install &amp;lt;包名&amp;gt; root@localhost:~/df/packages# sudo apt-get install --reinstall -d `apt-cache depends nginx | grep depends | cut -d: f2 |tr -d &amp;quot;&amp;lt;&amp;gt;&amp;quot;` root@localhost:~/df/packages# sudo apt-get download `apt-cache depends nginx | grep depends | cut -d: f2 |tr -d &amp;quot;&amp;lt;&amp;gt;&amp;quot;`  3.</description>
    </item>
    
    <item>
      <title>frp内网穿透</title>
      <link>https://workerwork.github.io/posts/frp/</link>
      <pubDate>Thu, 14 May 2020 13:41:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/frp/</guid>
      <description>1. 正常情况一个内网主机与外网服务器的交互 以访问google为例
假设我们的主机IP是192.168.0.10，路由器LAN IP为192.168.0.1，WAN IP为211.22.145.234（这是一个公网IP), google 服务器 IP 为74.125.204.101。 1.主机构建HTTP请求数据包，目标IP为74.125.204.101，目标端口是80/443，源IP为192.168.0.10，源端口随机生成，假定为5000 2.主机检查目标IP地址，发现不在一个网段，数据包丢给默认网关192.168.0.1 3.路由器LAN口收到数据包，构建NAT映射，随机生成端口，假定为5500,这样映射就是：5500-&amp;gt;192.168.0.10:5000． WIN口收到的数据包，如果目标端口是5500,则会转发给192.168.0.10的5000端口 4.路由器修改数据包的源端口为5500,源ＩＰ地址为211.22.145.234，使用WAN口将数据包发出去 5.google服务器收到请求，构建响应HTTP数据包，目标IP地址为211.22.145.234,目标端口是5500 6.路由器WAN口收到数据包，目标端口是5500,查询NAT表，发现对应的机器是192.168.0.10:5000， 所以修改目标IP为192.168.0.10，目标端口为5000，并通过LAN口发送给主机 7.主机收到数据包，完成一次通信  2. 内网穿透实现 测试服务器没有公网IP，想要让外网直接调用内网的服务，就需要用到内网穿透.
和使用路由器与外网交互类似，需要有一个第三方拥有公网IP的服务器进行路由的中转，代替路由器的角色.
由内网服务器主动请求公网服务器，建立一个长连接，这时公网服务器就可以随时随地的向内网服务器发送消息了
当使用浏览器想要访问内网服务时，先将请求发送到公网服务器上，公网服务器再通过之前建立的长连接将请求发送到内网服务器中。
从而实现在外网请求内网服务的需求
3. 公网服务器设置 # wget https://github.com/fatedier/frp/releases/download/v0.14.1/frp_0.14.1_linux_amd64.tar.gz # sudo tar zxf frp_0.14.1_linux_amd64.tar.gz # cd frp_0.14.1_linux_amd64/ # sudo vim frps.ini # [common] bind_port = 8989 # frp服务的端口 vhost_http_port = 8889 # frp的http服务的端口 # 启动服务 # ./frps -c frps.ini # 前台直接启动，测试看日志方便 # nohup ./frps -c ./frps.ini &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp; # 后台运行  4.</description>
    </item>
    
    <item>
      <title>github加速</title>
      <link>https://workerwork.github.io/posts/github-fast/</link>
      <pubDate>Tue, 05 May 2020 16:17:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/github-fast/</guid>
      <description>1. 给git设置socks5/vmess代理 前提是开启代理服务，可以使用V2rayL: https://github.com/jiangxufeng/v2rayL 和 ghelper
使用 https 的时候，就是使用 https 协议复制仓库的时候
git config --global http.proxy &#39;socks5://127.0.0.1:1080&#39; git config --global https.proxy &#39;socks5://127.0.0.1:1080&#39; git config --global http.proxy &#39;vmess://127.0.0.1:1081&#39; git config --global https.proxy &#39;vmess://127.0.0.1:1081&#39;  也可以直接修改用户主目录下的 .gitconfig 文件
[http] proxy = socks5://127.0.0.1:1080 [https] proxy = socks5://127.0.0.1:1080 [http] proxy = vmess://127.0.0.1:1081 [https] proxy = vmess://127.0.0.1:1081  取消代理
git config --global --unset http.proxy git config --global --unset https.proxy  查看已有代理
git config --global -l  在使用 git 开头的路径时，也就是在使用 ssh 通道时</description>
    </item>
    
    <item>
      <title>cpu亲和性</title>
      <link>https://workerwork.github.io/posts/affinity/</link>
      <pubDate>Mon, 20 Apr 2020 16:17:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/affinity/</guid>
      <description>1. 什么是cpu亲和性(affinity) CPU的亲和性， 就是进程要在指定的 CPU 上尽量长时间地运行而不被迁移到其他处理器，也称为CPU关联性； 再简单的点的描述就将制定的进程或线程绑定到相应的cpu上； 在多核运行的机器上，每个CPU本身自己会有缓存，缓存着进程使用的信息，而进程可能会被OS调度到其他CPU上， 如此，CPU cache命中率就低了，当绑定CPU后，程序就会一直在指定的cpu跑，不会由操作系统调度到其他CPU上，性能有一定的提高。
软亲和性(affinity): 就是进程要在指定的CPU上尽量长时间地运行而不被迁移到其他处理器，Linux内核进程调度器天生就具有被称为软CPU亲和性(affinity) 的特性，这意味着进程通常不会在处理器之间频繁迁移。 这种状态正是我们希望的，因为进程迁移的频率小就意味着产生的负载小。
硬亲和性(affinity): 简单来说就是利用linux内核提供给用户的API，强行将进程或者线程绑定到某一个指定的cpu核运行。
解释: 在linux内核中，所有的进程都有一个相关的数据结构，称为 task_struct。这个结构非常重要，原因有很多；其中与 亲和性（affinity）相关度最高的是 cpus_allowed 位掩码。 这个位掩码由 n 位组成，与系统中的 n 个逻辑处理器一一对应。 具有 4 个物理 CPU 的系统可以有 4 位。如果这些 CPU 都启用了超线程，那么这个系统就有一个 8 位的位掩码。 如果为给定的进程设置了给定的位，那么这个进程就可以在相关的 CPU 上运行。因此，如果一个进程可以在任何 CPU 上运行，并且能够根据需要在处理器之间进行迁移，那么位掩码就全是 1。 实际上，这就是 Linux 中进程的缺省状态;（这部分内容在这个博客中有提到一点：http://www.cnblogs.com/wenqiang/p/4802619.html）
cpus_allowed用于控制进程可以在哪里处理器上运行
sched_set_affinity() （用来修改位掩码）
sched_get_affinity() （用来查看当前的位掩码）
2. 进程与cpu的绑定 sched_setaffinity可以将某个进程绑定到一个特定的CPU。你比操作系统更了解自己的程序，为了避免调度器愚蠢的调度你的程序，或是为了在多线程程序中避免缓存失效造成的开销，你可能会希望这样做
在进行进程与cpu的绑定前，我们先了解编写程序需要准备的知识点
SCHED_SETAFFINITY(2) Linux Programmer&#39;s Manual SCHED_SETAFFINITY(2) NAME sched_setaffinity, sched_getaffinity - set and get a process&#39;s CPU affinity mask SYNOPSIS #define _GNU_SOURCE /* See feature_test_macros(7) */ #include &amp;lt;sched.</description>
    </item>
    
    <item>
      <title>CentOS7系统优化</title>
      <link>https://workerwork.github.io/posts/centos-good/</link>
      <pubDate>Fri, 30 Aug 2019 14:03:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/centos-good/</guid>
      <description>1. 修改ip地址、网关、主机名、DNS等 [root@localhost ~]# vi /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=eth0 #网卡名字 BOOTPROTO=static #静态IP地址获取状态 如：DHCP表示自动获取IP地址 IPADDR=192.168.1.113 #IP地址 NETMASK=255.255.255.0 #子网掩码 ONBOOT=yes#引导时是否激活 GATEWAY=192.168.1.1 [root@localhost ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=eth0 BOOTPROTO=static IPADDR=192.168.1.113 NETMASK=255.255.255.0 ONBOOT=yes GATEWAY=192.168.1.1 [root@localhost ~]# vi /etc/sysconfig/network HOSTNAME=c64 #修改主机名，重启生效 GATEWAY=192.168.1.1 #修改默认网关,如果上面eth0里面不配置网关的话，默认就使用这里的网关了。 [root@localhost ~]# cat /etc/sysconfig/network HOSTNAME=c64 GATEWAY=192.168.1.1 我们也可以用 hostnamec64 来临时修改主机名，重新登录生效 修改DNS [root@localhost ~]# vi /etc/resolv.conf #修改DNS信息 nameserver 114.114.114.114 nameserver 8.8.8.8 [root@localhost ~]# cat /etc/resolv.conf #查看修改后的DNS信息 nameserver 114.114.114.114 nameserver 8.8.8.8 [root@localhost ~]# systemctl restart network #重启网卡，生效  2.</description>
    </item>
    
    <item>
      <title>CentOS7安全加固</title>
      <link>https://workerwork.github.io/posts/security/</link>
      <pubDate>Fri, 30 Aug 2019 11:01:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/security/</guid>
      <description>1. 账号和口令 1 ）禁用或删除无用账号 减少系统无用账号，降低安全风险
#删除不必要的账号 userdel &amp;lt;用户名&amp;gt; #锁定不必要的账号 passwd -l &amp;lt;用户名&amp;gt; #解锁必要的账号 passwd -u &amp;lt;用户名&amp;gt;  2 ）检查特殊账号 检查是否存在空口令和root权限的账号
#查看空口令账号 awk -F: &#39;($2==&amp;quot;&amp;quot;)&#39; /etc/shadow #为空口令账号设定密码 passwd &amp;lt;用户名&amp;gt; #查看UID为零的账号，确认只有root账号 awk -F: &#39;($3==0)&#39; /etc/passwd  3 ）添加口令策略 加强口令的复杂度，降低被猜解的可能性
vi /etc/login.defs 修改配置文件 PASS_MAX_DAYS 90 #新建用户的密码最长使用天数 PASS_MIN_DAYS 0 #新建用户的密码最短使用天数 PASS_WARN_AGE 7 #新建用户的密码到期提前提醒天数 #或者使用chage命令修改用户设置 #将此用户的密码最长使用天数设为30，最短使用天数设为0，密码2000年1月1日过期，过期前七天警告用户 chage -m 0 -M 30 -E 2000-01-01 -W 7 &amp;lt;用户名&amp;gt; #设置连续输错三次密码，账号锁定五分钟 vi /etc/pam.d/common-auth 修改配置文件，添加 auth required pam_tally.so onerr=fail deny=3 unlock_time=300  4 ）限制用户su 限制能su到root的用户</description>
    </item>
    
    <item>
      <title>制作CentOS ISO</title>
      <link>https://workerwork.github.io/posts/centos-iso/</link>
      <pubDate>Wed, 28 Aug 2019 16:37:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/centos-iso/</guid>
      <description>1. 复制光盘文件 1）挂载iso镜像 #创建目录用于挂载光盘 mkdir /root/centos7 #挂载iso镜像 mount -o loop CentOS-7.0-1406-x86_64-DVD.iso /root/centos7  2）复制光盘文件到编辑目录进行编辑 因为挂载上iso镜像是只读的，如果要编辑，需要将文件复制出来，再编辑。
#首先创建编辑目录： mkdir /root/centos7_iso #复制光盘文件： cp -rf /root/centos7/* /root/centos7_iso/ #diskinfo treeinfo文件需单独拷贝下： cp /root/centos7/.discinfo /root/centos7_iso/ cp /root/centos7/.treeinfo /root/centos7_iso/  2. 编辑ks.cfg文件 系统安装的时候，按照ks.cfg文件的内容进行安装，我们把ks.cfg文件放到isolinux目录下：
cd /root/centos7_iso/isolinux  vim ks-init.cfg #platform=x86, AMD64, or Intel EM64T #version=DEVEL # Install OS instead of upgrade install # Keyboard layouts keyboard &#39;us&#39; # Root password rootpw --iscrypted $1$JtB/A66X$GCT7X3FCJVAPGd3sEY0mx0 # System language lang en_US # System authorization information auth --useshadow --passalgo=sha512 # Use cdrom installation media cdrom # Use text mode install #text graphical # SELinux configuration selinux --disabled # Do not configure the X Window System skipx #firstboot --enable #ignoredisk --only-use=sda # Firewall configuration firewall --disabled # Network information network --bootproto=dhcp --device=eth0 --onboot=no network --hostname=localhost.</description>
    </item>
    
    <item>
      <title>搭建本地yum仓库</title>
      <link>https://workerwork.github.io/posts/local-yum/</link>
      <pubDate>Wed, 28 Aug 2019 15:00:21 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/local-yum/</guid>
      <description>1. 安装工具 yum install -y createrepo  2. 编辑 comps.xml &amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt; &amp;lt;!DOCTYPE comps PUBLIC &amp;quot;-//CentOS//DTD Comps info//EN&amp;quot; &amp;quot;comps.dtd&amp;quot;&amp;gt; &amp;lt;comps&amp;gt; &amp;lt;group&amp;gt; &amp;lt;id&amp;gt;epc&amp;lt;/id&amp;gt; &amp;lt;name&amp;gt;epc&amp;lt;/name&amp;gt; &amp;lt;name xml:lang=&amp;quot;en_GB&amp;quot;&amp;gt;epc&amp;lt;/name&amp;gt; &amp;lt;description&amp;gt;epc installation.&amp;lt;/description&amp;gt; &amp;lt;default&amp;gt;false&amp;lt;/default&amp;gt; &amp;lt;uservisible&amp;gt;false&amp;lt;/uservisible&amp;gt; &amp;lt;packagelist&amp;gt; &amp;lt;packagereq type=&amp;quot;mandatory&amp;quot;&amp;gt;baicells-epc-base&amp;lt;/packagereq&amp;gt; &amp;lt;packagereq type=&amp;quot;mandatory&amp;quot;&amp;gt;baicells-epc-ui&amp;lt;/packagereq&amp;gt; &amp;lt;packagereq type=&amp;quot;mandatory&amp;quot;&amp;gt;baicells-epc-ovs-rest&amp;lt;/packagereq&amp;gt; &amp;lt;packagereq type=&amp;quot;mandatory&amp;quot;&amp;gt;baicells-epc-ovsdb-agent&amp;lt;/packagereq&amp;gt; &amp;lt;packagereq type=&amp;quot;mandatory&amp;quot;&amp;gt;baicells-epc-signaltrace&amp;lt;/packagereq&amp;gt; &amp;lt;packagereq type=&amp;quot;mandatory&amp;quot;&amp;gt;baicells-epc-gwsc&amp;lt;/packagereq&amp;gt; &amp;lt;packagereq type=&amp;quot;mandatory&amp;quot;&amp;gt;baicells-epc-openapi&amp;lt;/packagereq&amp;gt; &amp;lt;/packagelist&amp;gt; &amp;lt;/group&amp;gt; &amp;lt;/comps&amp;gt;  3. 创建仓库 createrepo -g comps.xml . #精确分组 #createrepo . #createrepo --update  4. 拷贝rpm包到仓库 mkdir rpms cp *.rpm rpms/  5.</description>
    </item>
    
  </channel>
</rss>