<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>WorkSpace</title>
    <link>https://workerwork.github.io/</link>
    <description>Recent content on WorkSpace</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 30 Nov 2020 12:09:51 +0800</lastBuildDate>
    
	<atom:link href="https://workerwork.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Linux 内核符号表</title>
      <link>https://workerwork.github.io/posts/system-map/</link>
      <pubDate>Mon, 30 Nov 2020 12:09:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/system-map/</guid>
      <description>1. 什么是符号(symbols) 什么是Symbol?
其实就是kernel中的变量(VariableName)或函数名称(Function Name)
这样可以方便程序员在写程序时可以直接参照这一份Symbol的索引文件，找到所需要的kernel信息，
这一份Symbol的索引文件又称为kernel symbol table
2. 内核符号表(Kernel Symbol Table) 内核符号表，就是在内核的内部函数或变量中，可供外部引用的函数和变量的符号表.
其实就是一个索引文件，它存在的目的就是让外部软件可以知道kernel文件内部实际分配的位置.
编译内核时，System.map文件用于存放内核符号表信息
System.map文件位于/或者/boot、/usr/src/linux/下
3. kallsyms 内核启动时候创建,供oops时定位错误，文件大小总为0，包含当前内核导出的、可供使用的变量或者函数；它只是内核数据的简单表示形式.
/proc/kallsyms是一个在启动时由Linux kernel实时产生的文件，当系统有任何变更时，它就会马上做出修正
可以理解为动态的符号表
4. 符号类型 | 符号类型 | 名称 | 说明 | | -| - | - | | A | Absolute | 符号的值是绝对值，并且在进一步链接过程中不会被改变 | | B | BSS | 符号在未初始化数据区或区（section）中，即在BSS段中 | | C | Common | 符号是公共的。公共符号是未初始化的数据。在链接时，多个公共符号可能具有同一名称。如果该符号定义在其他地方，则公共符号被看作是未定义的引用 | | D | Data | 符号在已初始化数据区中 | | G | Global | 符号是在小对象已初始化数据区中的符号。某些目标文件的格式允许对小数据对象（例如一个全局整型变量）可进行更有效的访问 | | I | Inderect | 符号是对另一个符号的间接引用 | | N | Debugging | 符号是一个调试符号 | | R | Read only | 符号在一个只读数据区中 | | S | Small | 符号是小对象未初始化数据区中的符号 | | T | Text | 符号是代码区中的符号 | | U | Undefined | 符号是外部的，并且其值为0（未定义 | | - | Stabs | 符号是a.</description>
    </item>
    
    <item>
      <title>Linux 内核调试 kdump vmcore</title>
      <link>https://workerwork.github.io/posts/vmcore/</link>
      <pubDate>Wed, 28 Oct 2020 11:42:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/vmcore/</guid>
      <description>1. kdump介绍 linux内核发送崩溃时，kdump会生成一个内核转储文件vmcore。 可以通过分析vmcore分析出内核崩溃的原因.
crash是一个被广泛应用的内核奔溃转储文件分析工具.
使用crash调试内核转储文件，需要安装crash工具和内核调试工具kernel-debuginfo.
2. 安装kdump crash kexec-tools 一般在系统镜像文件中就有相对应的rpm包
3. 配置kdump vim /boot/grub/menu.lst： 设置 crashkernel=auto vim /etc/kdump.conf： path /var/crash （core文件产生的目录）  4. 启动kdump systemctl start kdump  5. 安装kernel-debuginfo 下载内核版本对应的文件 kernel-debuginfo-3.10.0-957.el7.x86_64.rpm kernel-debuginfo-common-x86_64-3.10.0-957.el7.x86_64.rpm  6. 分析vmcore abrt-cli list crash /usr/lib/debug/lib/modules/3.10.0-957.el7.x86_64/vmlinux vmcore crash&amp;gt; bt PID: 7473 TASK: ffff9027d874bf40 CPU: 0 COMMAND: &amp;quot;cat&amp;quot; #0 [ffff9026d0ea3638] machine_kexec at ffffffffbd060b2a #1 [ffff9026d0ea3698] __crash_kexec at ffffffffbd113402 #2 [ffff9026d0ea3768] crash_kexec at ffffffffbd1134f0 #3 [ffff9026d0ea3780] oops_end at ffffffffbd717778 #4 [ffff9026d0ea37a8] no_context at ffffffffbd706f98 #5 [ffff9026d0ea37f8] __bad_area_nosemaphore at ffffffffbd70702f #6 [ffff9026d0ea3848] bad_area_nosemaphore at ffffffffbd7071a0 #7 [ffff9026d0ea3858] __do_page_fault at ffffffffbd71a730 #8 [ffff9026d0ea38c0] do_page_fault at ffffffffbd71a925 #9 [ffff9026d0ea38f0] page_fault at ffffffffbd716768 [exception RIP: strcmp+32] RIP: ffffffffbd353d20 RSP: ffff9026d0ea39a0 RFLAGS: 00010202 RAX: 000000000000002f RBX: ffff90240da5a080 RCX: 0000000000000000 RDX: 0000000000000000 RSI: 0000000000000001 RDI: ffff9026cd27fc11 RBP: ffff9026d0ea39a0 R8: 00000000004b1de2 R9: ffff9026cd27fc10 R10: ffff90253fc01d00 R11: ffffc0428c349fc0 R12: 0000000000000001 R13: ffff9026cd27fc10 R14: 0000000000000001 R15: ffff9027c16f1580 ORIG_RAX: ffffffffffffffff CS: 0010 SS: 0018 #10 [ffff9026d0ea39a8] send_log at ffffffffc0c22fd5 [xx] #11 [ffff9026d0ea3ac0] user_file at ffffffffc0c0c571 [xx] #12 [ffff9026d0ea3f00] sys_open at ffffffffc0c56670 [xxt] #13 [ffff9026d0ea3f50] system_call_fastpath at ffffffffbd71f7d5 RIP: 00007f2e860c2a30 RSP: 00007fff6d8755a8 RFLAGS: 00010202 RAX: 0000000000000002 RBX: 00007fff6d875868 RCX: 000000000060bc60 RDX: 1fffffffffff0000 RSI: 0000000000000000 RDI: 00007fff6d876293 RBP: 0000000000001000 R8: 0000000000000000 R9: 0000000000000000 R10: 00007fff6d875020 R11: 0000000000000246 R12: 0000000000402644 R13: 0000000000010000 R14: 0000000000000000 R15: 0000000000000000 ORIG_RAX: 0000000000000002 CS: 0033 SS: 002b crash&amp;gt; dis -l ffffffffbd353d20 /usr/src/debug/kernel-3.</description>
    </item>
    
    <item>
      <title>vpp-cli命令行总结</title>
      <link>https://workerwork.github.io/posts/vpp-cli/</link>
      <pubDate>Thu, 17 Sep 2020 17:37:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/vpp-cli/</guid>
      <description>1. 介绍 vpp网络协议栈配备了一组调试命令。访问CLI（具有适当权限）的最简单方法是使用vppctl命令:
sudo vppctl &amp;lt;cli command&amp;gt;  CLI解析器匹配静态的关键字字符串后，调用动作执行函数。 你可以通过在代码源文件中搜索VLIB_CLI_COMMAND宏的来查找CLI命令的源代码.
2. 调试和Telnet CLI 使用unix交互式参数或启动配置选项启用调试CLI。 这会导致VPP不以守护进程的情况启动，并在运行它的终端上显示命令行界面.
使用cli-listen localhost:5002选项启用Telnet CLI，这将导致VPP侦听localhost地址端口5002上的TCP连接。 然后，Telnet客户端可以连接到此端口（例如，telnet localhost 5002）并将收到命令行提示符。
以下配置将启用这两种机制：
unix { interactive cli-listen localhost:5002 }  CLI以横幅图形（可以禁用）和命令行提示符提示CLI开始。对于VPP的发布版本，命令行提示符通常为“vpp”， 对于启用了调试功能的开发版本，命令行提示符为“DBGvpp＃”,可以通过unix cli-prompt设置命令行提示符， 并通过unix cli-no-banner来禁止横幅.
3. CLI特征  &amp;lt;-或-&amp;gt; 左右光标键，在命令行内移动光标。 Ctrl-左/右将向左或向右搜索下一个单词的开头。 Home / end将光标跳转到行的开头和结尾。 可以使用exit命令关闭CLI。 或者，空输入行上的^ D也将关闭会话。关闭调试会话也将关闭VPP  4. 命令行参数与配置文件 VPP网络协议栈可以在命令行或配置文件中提供配置参数。 您可以通过搜索VLIB_CONFIG_FUNCTION宏在源代码中找到命令行参数解析器的相关代码。 调用VLIB_CONFIG_FUNCTION（foo_config，“foo”）将使函数foo_config接收名为“foo”的参数块中给出的所有参数， 例如：“foo {arg1 arg2 arg3 &amp;hellip;}”
VPP应用程序必须能够找到自己的可执行映像。确保这一点最简单方法是通过给出其绝对路径来调用VPP应用程序;
例如：/usr/bin/vpp 。
在启动时，VPP应用程序通过解析自己的ELF段以生成初始化，配置和退出处理程序的列表
配置文件：
还可以在启动配置文件中提供命令行参数，配置文件的路径在命令行上提供给VPP应用程序。
配置文件的格式是一个简单的文本文件，其内容与命令行相同，但是能够使用换行符使内容更加易于阅读。 例如：
unix { nodaemon /var/log/vpp/vpp.log full-coredump cli-listen localhost:5002 } api-trace { on } dpdk { dev 0000:03:00.</description>
    </item>
    
    <item>
      <title>Shared Memory</title>
      <link>https://workerwork.github.io/posts/shm/</link>
      <pubDate>Fri, 21 Aug 2020 09:22:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/shm/</guid>
      <description>1. Shared Memory介绍 共享内存是System V版本的最后一个进程间通信方式。共享内存，顾名思义就是允许两个不相关的进程访问同一个逻辑内存， 共享内存是两个正在运行的进程之间共享和传递数据的一种非常有效的方式。不同进程之间共享的内存通常为同一段物理内存。 进程可以将同一段物理内存连接到他们自己的地址空间中，所有的进程都可以访问共享内存中的地址。 如果某个进程向共享内存写入数据，所做的改动将立即影响到可以访问同一段共享内存的任何其他进程.
特别提醒：共享内存并未提供同步机制，也就是说，在第一个进程结束对共享内存的写操作之前， 并无自动机制可以阻止第二个进程开始对它进行读取，所以我们通常需要用其他的机制来同步对共享内存的访问，例如信号量.
2. C语言demo程序 //comm.h #ifndef _COMM_H__ #define _COMM_H__ #include&amp;lt;stdio.h&amp;gt; #include&amp;lt;sys/types.h&amp;gt; #include&amp;lt;sys/ipc.h&amp;gt; #include&amp;lt;sys/shm.h&amp;gt; #define PATHNAME &amp;quot;.&amp;quot; #define PROJ_ID 0x6666 int CreateShm(int size); int DestroyShm(int shmid); int GetShm(int size); #endif  //comm.c #include&amp;quot;comm.h&amp;quot; static int CommShm(int size,int flags) { key_t key = ftok(PATHNAME,PROJ_ID); if(key &amp;lt; 0) { perror(&amp;quot;ftok&amp;quot;); return -1; } int shmid = 0; if((shmid = shmget(key,size,flags)) &amp;lt; 0) { perror(&amp;quot;shmget&amp;quot;); return -2; } return shmid; } int DestroyShm(int shmid) { if(shmctl(shmid,IPC_RMID,NULL) &amp;lt; 0) { perror(&amp;quot;shmctl&amp;quot;); return -1; } return 0; } int CreateShm(int size) { return CommShm(size,IPC_CREAT | IPC_EXCL | 0666); } int GetShm(int size) { return CommShm(size,IPC_CREAT); }  //client.</description>
    </item>
    
    <item>
      <title>Unix domain socket</title>
      <link>https://workerwork.github.io/posts/uds/</link>
      <pubDate>Wed, 19 Aug 2020 15:29:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/uds/</guid>
      <description>1. Unix domain socket介绍 Unix domain socket 又叫 IPC(inter-process communication 进程间通信) socket，用于实现同一主机上的进程间通信. socket 原本是为网络通讯设计的，但后来在 socket 的框架上发展出一种 IPC 机制，就是 UNIX domain socket. 虽然网络 socket 也可用于同一台主机的进程间通讯(通过 loopback 地址 127.0.0.1)，但是 UNIX domain socket 用于 IPC更有效率：不需要经过网络协议栈，不需要打包拆包、计算校验和、维护序号和应答等，只是将应用层数据从一个进程拷贝到另一个进程. 这是因为，IPC机制本质上是可靠的通讯，而网络协议是为不可靠的通讯设计的. UNIX domain socket 是全双工的，API 接口语义丰富，相比其它 IPC 机制有明显的优越性，目前已成为使用最广泛的 IPC 机制， 比如 X Window 服务器和 GUI 程序之间就是通过 UNIX domain socket 通讯的. Unix domain socket 是 POSIX 标准中的一个组件，所以不要被名字迷惑，linux 系统也是支持它的.
2. C语言demo程序 下面是一个非常简单的服务器端程序，它从客户端读字符，然后将每个字符转换为大写并回送给客户端
#include &amp;lt;stdlib.h&amp;gt; #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;stddef.h&amp;gt; #include &amp;lt;sys/socket.</description>
    </item>
    
    <item>
      <title>video server</title>
      <link>https://workerwork.github.io/posts/video-server/</link>
      <pubDate>Wed, 19 Aug 2020 13:13:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/video-server/</guid>
      <description>1. SRS介绍 SRS/3.0，OuXuli，是一个流媒体集群，支持RTMP/HLS/WebRTC/SRT/GB28181，高效、稳定、易用，简单而快乐。 101 SRS is a RTMP/HLS/WebRTC/SRT/GB28181 streaming cluster, high efficiency, stable and simple.
项目地址: https://github.com/ossrs/srs
2. 运行docker容器启动srs服务 sudo docker run -d -p 1935:1935 -p 1985:1985 -p 8080:8080 ossrs/srs:3  3. 使用ffmpeg推流 需要安装ffmpeg
./pushflow.sh cat pushflow.sh #!/bin/bash while : do sudo ffmpeg -re -i dog.mp4 -vcodec copy -acodec copy -f flv -y rtmp://192.168.1.7:1935/live/livestream sleep 1 done  4. 终端使用vlc播放器拉流 视频地址填写: rtmp://192.168.1.7:1935/live/livestream
5. 使用live555支持rtsp 需要添加网关以指定监听地址 可以使用ffmpeg来转换视频源格式
ffmpeg -i dance.mp4 -codec copy -bsf: h264_mp4toannexb -f h264 dance.</description>
    </item>
    
    <item>
      <title>openssh8.1 rpm build</title>
      <link>https://workerwork.github.io/posts/openssh/</link>
      <pubDate>Fri, 14 Aug 2020 15:36:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/openssh/</guid>
      <description>1. 创建工作路径 mkdir -p /root/rpmbuild/{SOURCES,SPECS} cp openssh-8.1p1.tar.gz /root/rpmbuild/SOURCES/  2. 下载源码包 wget https://openbsd.hk/pub/OpenBSD/OpenSSH/portable/openssh-8.1p1.tar.gz  3. 制作准备 yum install rpm-build zlib-devel openssl-devel gcc perl-devel pam-devel unzip tar -zxf openssh-8.1p1.tar.gz cp ./openssh-8.1p1/contrib/redhat/openssh.spec . sed -i -e &amp;quot;s/%define no_x11_askpass 0/%define no_x11_askpass 1/g&amp;quot; openssh.spec sed -i -e &amp;quot;s/%define no_gnome_askpass 0/%define no_gnome_askpass 1/g&amp;quot; openssh.spec  4. 制作rpm包 rpmbuild -ba openssh.spec 如果出现 错误：构建依赖失败： openssl-devel &amp;lt; 1.1 被 ?? 需要 解决方法： vi openssh.spec 注释掉 BuildRequires: openssl-devel &amp;lt; 1.</description>
    </item>
    
    <item>
      <title>自建kvm虚拟机</title>
      <link>https://workerwork.github.io/posts/kvm2/</link>
      <pubDate>Wed, 22 Jul 2020 10:35:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/kvm2/</guid>
      <description>1. 自定义虚拟机 egrep -q &amp;quot;(svm|vmx)&amp;quot; /proc/cpuinfo &amp;amp;&amp;amp; echo &amp;quot;yes&amp;quot; lsmod|grep kvm # centos yum install -y qemu-kvm #KVM主程序，KVM虚拟化模块 yum install -y libvirt #虚拟化服务库 yum install -y bridge-utils ln -s /usr/libexec/qemu-kvm /usr/bin/qemu-kvm # ubuntu apt install qemu qemu-kvm apt install libvirt-bin apt install bridge-utils ln -s /usr/bin/qemu-system-x86_64 /usr/bin/qemu-kvm systemctl start libvirtd systemctl enable libvirtd qemu-img create -f qcow2 vm_NGC.img 20G #创建磁盘镜像 qemu-kvm -name vm_NGC -m 4096 -cpu host -enable-kvm -smp 8 -hda vm_NGC.</description>
    </item>
    
    <item>
      <title>DPDK-Devbind</title>
      <link>https://workerwork.github.io/posts/dpdk-devbind/</link>
      <pubDate>Tue, 30 Jun 2020 17:18:27 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/dpdk-devbind/</guid>
      <description>dpdk-devbind.py #! /usr/bin/env python # SPDX-License-Identifier: BSD-3-Clause # Copyright(c) 2010-2014 Intel Corporation # import sys import os import getopt import subprocess from os.path import exists, abspath, dirname, basename # The PCI base class for all devices network_class = {&#39;Class&#39;: &#39;02&#39;, &#39;Vendor&#39;: None, &#39;Device&#39;: None, &#39;SVendor&#39;: None, &#39;SDevice&#39;: None} encryption_class = {&#39;Class&#39;: &#39;10&#39;, &#39;Vendor&#39;: None, &#39;Device&#39;: None, &#39;SVendor&#39;: None, &#39;SDevice&#39;: None} intel_processor_class = {&#39;Class&#39;: &#39;0b&#39;, &#39;Vendor&#39;: &#39;8086&#39;, &#39;Device&#39;: None, &#39;SVendor&#39;: None, &#39;SDevice&#39;: None} cavium_sso = {&#39;Class&#39;: &#39;08&#39;, &#39;Vendor&#39;: &#39;177d&#39;, &#39;Device&#39;: &#39;a04b,a04d&#39;, &#39;SVendor&#39;: None, &#39;SDevice&#39;: None} cavium_fpa = {&#39;Class&#39;: &#39;08&#39;, &#39;Vendor&#39;: &#39;177d&#39;, &#39;Device&#39;: &#39;a053&#39;, &#39;SVendor&#39;: None, &#39;SDevice&#39;: None} cavium_pkx = {&#39;Class&#39;: &#39;08&#39;, &#39;Vendor&#39;: &#39;177d&#39;, &#39;Device&#39;: &#39;a0dd,a049&#39;, &#39;SVendor&#39;: None, &#39;SDevice&#39;: None} cavium_tim = {&#39;Class&#39;: &#39;08&#39;, &#39;Vendor&#39;: &#39;177d&#39;, &#39;Device&#39;: &#39;a051&#39;, &#39;SVendor&#39;: None, &#39;SDevice&#39;: None} cavium_zip = {&#39;Class&#39;: &#39;12&#39;, &#39;Vendor&#39;: &#39;177d&#39;, &#39;Device&#39;: &#39;a037&#39;, &#39;SVendor&#39;: None, &#39;SDevice&#39;: None} avp_vnic = {&#39;Class&#39;: &#39;05&#39;, &#39;Vendor&#39;: &#39;1af4&#39;, &#39;Device&#39;: &#39;1110&#39;, &#39;SVendor&#39;: None, &#39;SDevice&#39;: None} network_devices = [network_class, cavium_pkx, avp_vnic] crypto_devices = [encryption_class, intel_processor_class] eventdev_devices = [cavium_sso, cavium_tim] mempool_devices = [cavium_fpa] compress_devices = [cavium_zip] # global dict ethernet devices present.</description>
    </item>
    
    <item>
      <title>keepalived应用</title>
      <link>https://workerwork.github.io/posts/keepalived/</link>
      <pubDate>Tue, 30 Jun 2020 14:23:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/keepalived/</guid>
      <description>1. 监控脚本 在Master节点和Slave节点 /etc/keepalived目录下添加check_nginx.sh 文件，用于检测Nginx的存活状况
#!/bin/bash #时间变量，用于记录日志 d=`date --date today +%Y%m%d_%H:%M:%S` #计算nginx进程数量 n=`ps -C nginx --no-heading|wc -l` #如果进程为0，则尝试启动nginx，并且再次检测nginx进程数量， #如果还为0，说明nginx无法启动，此时需要关闭keepalived if [ $n -eq &amp;quot;0&amp;quot; ]; then #如果挂掉了，就启动nginx #注意nginx.conf配置文件的位置 #尝试重新启动nginx /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf sleep 3 #睡眠3秒 n2=`ps -C nginx --no-heading|wc -l` if [ $n2 -eq &amp;quot;0&amp;quot; ]; then #把nginx宕机时间写入日志 echo &amp;quot;$d nginx down,keepalived will stop&amp;quot; &amp;gt;&amp;gt; /usr/local/nginx/logs/check_ng.log #启动失败，将keepalived服务杀死。将vip漂移到其它备份节点 service keepalived stop fi fi  授权: chmod 755 /etc/keepalived/check_nginx.sh
2. 非抢占模式 在Master 节点 /etc/keepalived目录下，配置keepalived.</description>
    </item>
    
    <item>
      <title>网卡命名</title>
      <link>https://workerwork.github.io/posts/eth-name/</link>
      <pubDate>Tue, 30 Jun 2020 10:25:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/eth-name/</guid>
      <description>1. 背景 服务器通常有多块网卡，有板载集成的，同时也有插在PCIe插槽的.
Linux系统的命名原来是eth0,eth1这样的形式，但是这个编号往往不一定准确对应网卡接口的物理顺序.
为解决这类问题，dell开发了biosdevname方案.
systemd v197版本中将dell的方案作了进一步的一般化拓展.
linux内核启动过程中，会默认给网卡以ethX方式随机命名，然后再通过systemd去rename成其他名称.
2. rename流程 step1 依据/usr/lib/udev/rules.d/60-net.rules， 查看是否有ifcfg-xx配置文件（路径在/etc/sysconfig/network-scripts/), 是否有定义了指定MAC地址的配置文件（ifcfg-xx ，xx必须和配置文件的内容DEVICE一致），如果有，则命名改网卡； step2 依据/usr/lib/udev/rules.d/71-biosdevname.rules，如果biosdevname使能了（安装了biosdevname这个包，且内核启动参数显式设置为1）， 且网卡没有在step1中定义，则按照biosdevname命名规则rename网卡；（注意，如果没有安装biosdevname这个包，就没有这个文件） step3, 依据/lib/udev/rules.d/75-net-description.rules，将udev工具会根据device属性将填写网卡的属性命名，可能一个网卡会有多个维度的名称; step4，udev 根据step3中的赋值，按照指定的scheme规则，去给在step1 step2中没有命名的网卡命名; 强调：这个step顺序是在我们没有自定义自己的rules的前提下，如果用户自定义了自己的rules，则用户自定义为优先级最高  3. 命令策略(scheme规则) 1.如果从BIOS中能够取到可用的，板载网卡的索引号，则使用这个索引号命名，例如: eno1，如不能则尝试2 2.如果从BIOS中能够取到可以用的，网卡所在的PCI-E热插拔插槽(注：pci槽位号)的索引号，则使用这个索引号命名，例如: ens1，如不能则尝试3 3.如果能拿到设备所连接的物理位置（PCI总线号+槽位号？）信息，则使用这个信息命名，例如:enp2s0，如不能则尝试4 4.传统的kernel命名方法，例如: eth0，这种命名方法的结果不可预知的，即可能第二块网卡对应eth0，第一块网卡对应eth1 5.使用网卡的MAC地址来命名，这个方法一般不使用 同一个网卡通常同时具有多个维度的名称，systemd在选取的时候，按照有先后次序，使用先命中的 顺序可以简单理解为(eno1-ens1-enp1) root@Bai5gc:/sys/class/net/eth1# udevadm info /sys/class/net/eth1 P: /devices/pci0000:00/0000:00:02.2/0000:03:00.0/net/eth1 E: DEVPATH=/devices/pci0000:00/0000:00:02.2/0000:03:00.0/net/eth1 E: ID_BUS=pci E: ID_MODEL_FROM_DATABASE=Ethernet Connection X552 10 GbE Backplane E: ID_MODEL_ID=0x15ab E: ID_NET_DRIVER=ixgbe E: ID_NET_LINK_FILE=/lib/systemd/network/99-default.link E: ID_NET_NAME_MAC=enxb4a9fca897e7 E: ID_NET_NAME_ONBOARD=eno3 E: ID_NET_NAME_PATH=enp3s0f0 E: ID_PATH=pci-0000:03:00.0 E: ID_PATH_TAG=pci-0000_03_00_0 E: ID_PCI_CLASS_FROM_DATABASE=Network controller E: ID_PCI_SUBCLASS_FROM_DATABASE=Ethernet controller E: ID_VENDOR_FROM_DATABASE=Intel Corporation E: ID_VENDOR_ID=0x8086 E: IFINDEX=3 E: INTERFACE=eth1 E: SUBSYSTEM=net E: SYSTEMD_ALIAS=/sys/subsystem/net/devices/eth1 E: TAGS=:systemd: E: USEC_INITIALIZED=5061037 E: net.</description>
    </item>
    
    <item>
      <title>vpp编译分析</title>
      <link>https://workerwork.github.io/posts/vpp-debs/</link>
      <pubDate>Mon, 15 Jun 2020 09:34:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/vpp-debs/</guid>
      <description>1. 下载源码 git clone http://192.168.9.105:60080/UPF/upf-vpp.git  2. 编译选项 1.make install-dep #install software dependencies 2.make wipe(wipe-release) #wipe all products 3.make build(build-release) #build binaries 4.make install-ext-deps #install external development dependencies(about dpdk) 5.make pkg-deb #build DEB packages  3. deb包 root@localhost:/home/ubuntu/work/upf-vpp# ll build-root/*.deb -rw-r--r-- 1 root root 184920 Jun 22 19:33 build-root/libvppinfra_19.08.1-21~g512cdac9c-dirty_amd64.deb -rw-r--r-- 1 root root 145112 Jun 22 19:33 build-root/libvppinfra-dev_19.08.1-21~g512cdac9c-dirty_amd64.deb -rw-r--r-- 1 root root 22456 Jun 22 19:33 build-root/python3-vpp-api_19.08.1-21~g512cdac9c-dirty_amd64.deb -rw-r--r-- 1 root root 3313088 Jun 22 19:33 build-root/vpp_19.</description>
    </item>
    
    <item>
      <title>ubuntu18.04使用xrdp远程桌面</title>
      <link>https://workerwork.github.io/posts/remote-desktop/</link>
      <pubDate>Thu, 11 Jun 2020 09:01:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/remote-desktop/</guid>
      <description>1. 执行下面的脚本安装 http://www.c-nergy.be/downloads/install-xrdp-3.0.zip
root@dongfeng-virtual-machine:/home/dongfeng# cat Install-xrdp-3.0.sh #!/bin/bash ##################################################################################################### # Script_Name : install-xrdp-3.0.sh # Description : Perform a custom installation of xrdp # on ubuntu 18.04 and later # Date : May 2019 # written by : Griffon # Web Site :http://www.c-nergy.be - http://www.c-nergy.be/blog # Version : 3.0 # History : 3.0 - Added support for Ubuntu 19.04 # - New code for Look&#39;n feel using xsessionrc method # - New code for enabling Sound Redirection - compiling from source # - Removed -g parameter # : 2.</description>
    </item>
    
    <item>
      <title>使用rust语言&#43;SDL2库写游戏</title>
      <link>https://workerwork.github.io/posts/rust-game/</link>
      <pubDate>Mon, 08 Jun 2020 15:57:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/rust-game/</guid>
      <description>1. 安装rust curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh  2. 设置rust国内源 #当前用户目录下 /linuxidc/.cargo/ 的.cargo 文件夹，进入.cargo 当前目录，在当前目下创建 config 文件 source.crates-io] registry = &amp;quot;https://github.com/rust-lang/crates.io-index&amp;quot; replace-with = &#39;ustc&#39; [source.ustc] registry = &amp;quot;git://mirrors.ustc.edu.cn/crates.io-index&amp;quot;  3. 安装SDL库 dnf install SDL2 dnf install SDL2-devel dnf install SDL2_image-devel dnf install SDL2_gfx-devel dnf install SDL2_mixer-devel dnf install SDL2_ttf-devel  4. 创建rust项目 cargo new testSDL cd testSDL 编辑cargo.toml，加入sdl2依赖 [dongfeng@localhost testSDL]$ cat Cargo.toml [package] name = &amp;quot;testsdl&amp;quot; version = &amp;quot;0.</description>
    </item>
    
    <item>
      <title>搭建本地apt仓库</title>
      <link>https://workerwork.github.io/posts/local-apt/</link>
      <pubDate>Mon, 25 May 2020 14:34:21 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/local-apt/</guid>
      <description>1. 安装工具 #apt-get install dpkg-dev #这个比较全 apt-get install gnupg apt-get install rng-tools  2. 搜集软件和依赖 # 查询依赖关系 root@localhost:~/df/packages# apt-cache depends nginx nginx |Depends: nginx-core |Depends: nginx-full |Depends: nginx-light Depends: nginx-extras |Depends: nginx-core |Depends: nginx-full |Depends: nginx-light Depends: nginx-extras # 下载 sudo rm -rf /var/cache/apt/archives/* # 清空缓存目录，这一步也可以不做 sudo apt-get -d install &amp;lt;包名&amp;gt; root@localhost:~/df/packages# sudo apt-get install --reinstall -d `apt-cache depends nginx | grep depends | cut -d: f2 |tr -d &amp;quot;&amp;lt;&amp;gt;&amp;quot;` root@localhost:~/df/packages# sudo apt-get download `apt-cache depends nginx | grep depends | cut -d: f2 |tr -d &amp;quot;&amp;lt;&amp;gt;&amp;quot;`  3.</description>
    </item>
    
    <item>
      <title>frp内网穿透</title>
      <link>https://workerwork.github.io/posts/frp/</link>
      <pubDate>Thu, 14 May 2020 13:41:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/frp/</guid>
      <description>1. 正常情况一个内网主机与外网服务器的交互 以访问google为例
假设我们的主机IP是192.168.0.10，路由器LAN IP为192.168.0.1，WAN IP为211.22.145.234（这是一个公网IP), google 服务器 IP 为74.125.204.101。 1.主机构建HTTP请求数据包，目标IP为74.125.204.101，目标端口是80/443，源IP为192.168.0.10，源端口随机生成，假定为5000 2.主机检查目标IP地址，发现不在一个网段，数据包丢给默认网关192.168.0.1 3.路由器LAN口收到数据包，构建NAT映射，随机生成端口，假定为5500,这样映射就是：5500-&amp;gt;192.168.0.10:5000． WIN口收到的数据包，如果目标端口是5500,则会转发给192.168.0.10的5000端口 4.路由器修改数据包的源端口为5500,源ＩＰ地址为211.22.145.234，使用WAN口将数据包发出去 5.google服务器收到请求，构建响应HTTP数据包，目标IP地址为211.22.145.234,目标端口是5500 6.路由器WAN口收到数据包，目标端口是5500,查询NAT表，发现对应的机器是192.168.0.10:5000， 所以修改目标IP为192.168.0.10，目标端口为5000，并通过LAN口发送给主机 7.主机收到数据包，完成一次通信  2. 内网穿透实现 测试服务器没有公网IP，想要让外网直接调用内网的服务，就需要用到内网穿透.
和使用路由器与外网交互类似，需要有一个第三方拥有公网IP的服务器进行路由的中转，代替路由器的角色.
由内网服务器主动请求公网服务器，建立一个长连接，这时公网服务器就可以随时随地的向内网服务器发送消息了
当使用浏览器想要访问内网服务时，先将请求发送到公网服务器上，公网服务器再通过之前建立的长连接将请求发送到内网服务器中。
从而实现在外网请求内网服务的需求
3. 公网服务器设置 # wget https://github.com/fatedier/frp/releases/download/v0.14.1/frp_0.14.1_linux_amd64.tar.gz # sudo tar zxf frp_0.14.1_linux_amd64.tar.gz # cd frp_0.14.1_linux_amd64/ # sudo vim frps.ini # [common] bind_port = 8989 # frp服务的端口 vhost_http_port = 8889 # frp的http服务的端口 # 启动服务 # ./frps -c frps.ini # 前台直接启动，测试看日志方便 # nohup ./frps -c ./frps.ini &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp; # 后台运行  4.</description>
    </item>
    
    <item>
      <title>编写pip包并上传到pypi</title>
      <link>https://workerwork.github.io/posts/pypi/</link>
      <pubDate>Sun, 10 May 2020 16:25:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/pypi/</guid>
      <description>1. 首先创建项目，目录结构如下 worker_package/ ├── LICENSE ├── README.md ├── setup.py └── workerwork ├── __init__.py └── models.py  其中 worker_package/workerwork 是主代码目录，setup.py 是必备的打包文件
setup.py
#!/usr/bin/env python # -*- coding:utf-8 -*- # Author: workerwork(workerwork@qq.com) # Description: from setuptools import setup, find_packages setup( name = &#39;workerwork&#39;, version = &#39;0.0.1&#39;, keywords=&#39;wow&#39;, description = &#39;a library for wow Developer&#39;, license = &#39;MIT License&#39;, url = &#39;&#39;, author = &#39;workerwork&#39;, author_email = &#39;workerwork@qq.com&#39;, packages = find_packages(), include_package_data = True, platforms = &#39;any&#39;, install_requires = [ &#39;requests&amp;gt;=2.</description>
    </item>
    
    <item>
      <title>p4实践环境</title>
      <link>https://workerwork.github.io/posts/p4/</link>
      <pubDate>Wed, 06 May 2020 18:00:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/p4/</guid>
      <description>1. 安装ubuntu16.04(18.04)并更新依赖 # sudo apt update # sudo apt-get install automake cmake libjudy-dev libpcap-dev libboost-dev \ libboost-test-dev libboost-program-options-dev libboost-system-dev \ libboost-filesystem-dev libboost-thread-dev libevent-dev libtool \ flex bison pkg-config g++ libssl-dev -y # sudo apt-get install cmake g++ git automake libtool libgc-dev bison flex libfl-dev \ libgmp-dev libboost-dev libboost-iostreams-dev libboost-graph-dev \ llvm pkg-config python python-scapy python-ipaddr python-ply tcpdump curl -y # sudo apt-get install libreadline6 libreadline6-dev python-pip python-scapy -y # sudo pip install psutil # sudo pip install crcmod  2.</description>
    </item>
    
    <item>
      <title>github加速</title>
      <link>https://workerwork.github.io/posts/github-fast/</link>
      <pubDate>Tue, 05 May 2020 16:17:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/github-fast/</guid>
      <description>1. 给git设置socks5/vmess代理 前提是开启代理服务，可以使用V2rayL: https://github.com/jiangxufeng/v2rayL 和 ghelper
使用 https 的时候，就是使用 https 协议复制仓库的时候
git config --global http.proxy &#39;socks5://127.0.0.1:1080&#39; git config --global https.proxy &#39;socks5://127.0.0.1:1080&#39; git config --global http.proxy &#39;vmess://127.0.0.1:1081&#39; git config --global https.proxy &#39;vmess://127.0.0.1:1081&#39;  也可以直接修改用户主目录下的 .gitconfig 文件
[http] proxy = socks5://127.0.0.1:1080 [https] proxy = socks5://127.0.0.1:1080 [http] proxy = vmess://127.0.0.1:1081 [https] proxy = vmess://127.0.0.1:1081  取消代理
git config --global --unset http.proxy git config --global --unset https.proxy  查看已有代理
git config --global -l  在使用 git 开头的路径时，也就是在使用 ssh 通道时</description>
    </item>
    
    <item>
      <title>vpp node-graph编排过程</title>
      <link>https://workerwork.github.io/posts/vpp-node-graph/</link>
      <pubDate>Thu, 30 Apr 2020 10:14:26 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/vpp-node-graph/</guid>
      <description>1. vpp node graph VPP处理报文时是沿着一个有向图进行处理的，每一个功能单元称之为节点(node)
2. 数据结构 静态数据结构 节点全局管理结构vlib_node_main_t
typedef struct { /* Public nodes. */ /* 节点指针数组，使用下标作为索引 */ vlib_node_t **nodes; /* Node index hashed by node name. */ /* 根据节点名字进行hash，可以根据节点名字进行hash表查找 * 只有main线程才会委会该hash表 */ uword *node_by_name; u32 flags; /* 该标志表示Runtime信息已经被初始化过了 */ #define VLIB_NODE_MAIN_RUNTIME_STARTED (1 &amp;lt;&amp;lt; 0) /* Nodes segregated by type for cache locality. Does not apply to nodes of type VLIB_NODE_TYPE_INTERNAL. */ vlib_node_runtime_t *nodes_by_type[VLIB_N_NODE_TYPE]; /* Node runtime indices for input nodes with pending interrupts.</description>
    </item>
    
    <item>
      <title>vpp 节点报文处理流程分析</title>
      <link>https://workerwork.github.io/posts/vpp-node-fw/</link>
      <pubDate>Wed, 29 Apr 2020 11:14:24 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/vpp-node-fw/</guid>
      <description>1. 以sample例子来分析vpp节点对报文的处理流程 vpp/src/examples/sample-plugin/sample $ll total 56 -rw-rw-r-- 1 ych ych 886 Apr 1 17:34 CMakeLists.txt -rw-rw-r-- 1 ych ych 17933 Apr 1 17:34 node.c -rw-rw-r-- 1 ych ych 712 Apr 1 17:34 sample_all_api_h.h -rw-rw-r-- 1 ych ych 1068 Apr 1 17:34 sample.api -rw-rw-r-- 1 ych ych 6569 Apr 1 17:34 sample.c -rw-rw-r-- 1 ych ych 1135 Apr 1 17:34 sample.h -rw-rw-r-- 1 ych ych 960 Apr 1 17:34 sample_msg_enum.h -rw-rw-r-- 1 ych ych 5512 Apr 1 17:34 sample_test.</description>
    </item>
    
    <item>
      <title>vpp sample plugin</title>
      <link>https://workerwork.github.io/posts/vpp-sample-plugin/</link>
      <pubDate>Tue, 28 Apr 2020 17:25:50 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/vpp-sample-plugin/</guid>
      <description>1. plugin_sample.c 在此文件中定义feature和cli
#include &amp;lt;vnet/plugin/plugin.h&amp;gt; #include &amp;lt;plugin_sample/plugin_sample.h&amp;gt; plugin_sample_main_t plugin_sample_main; //开关实现 int plugin_sample_enable_disable(u32 sw_if_index, //index int enable_disable)	//开关标识 { vnet_sw_interface_t *sw; int ret = 0; /* Utterly wrong? */ if (pool_is_free_index (plugin_sample_main.vnet_main-&amp;gt;interface_main.sw_interfaces, //vnet_main结构中的interface_main结构中的sw接口 sw_if_index)) //接口索引 return VNET_API_ERROR_INVALID_SW_IF_INDEX; /* Not a physical port? */ sw = vnet_get_sw_interface(plugin_sample_main.vnet_main,	//vnet_main结构 sw_if_index);	if (sw-&amp;gt;type != VNET_SW_INTERFACE_TYPE_HARDWARE) return VNET_API_ERROR_INVALID_SW_IF_INDEX; vnet_feature_enable_disable(&amp;quot;ip4-unicast&amp;quot;, //挂载节点 &amp;quot;plugin_sample&amp;quot;, sw_if_index, enable_disable, 0, 0); return ret; } static clib_error_t* plugin_sample_enable_disable_command_fn(vlib_main_t* vm,	//vlib_main结构 unformat_input_t *input, vlib_cli_command_t *cmd) { u32 sw_if_index = ~0;	//~0 取反= 1 int enable_disable = 1; while(unformat_check_input(input) !</description>
    </item>
    
    <item>
      <title>vpp feature</title>
      <link>https://workerwork.github.io/posts/vpp-feature/</link>
      <pubDate>Tue, 28 Apr 2020 15:00:18 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/vpp-feature/</guid>
      <description>1. 背景和概念  早期的VPP本身的node框架比较固定，各个node之间逻辑连接已经固化,为此新版本增加了feature机制.
 每个feature是一个node，用户可以启用/停止某个或某些feature
 用户也可以自己写插件，把自定义node（自己的业务逻辑）加入到指定位置
  2. 重要数据结构和操作函数 # # vnet_feature_arc_registration_t # ---------------------------------- # vpp将feature分成不同的组，每组feature称为一个arc # arc中的feature按照代码指定的顺序串接起来 # arc结构将记录这组feature的起始node和结束node # 系统初始化时完成每个feature的连接 # vnet/feature/feature.h +38 /** feature registration object */ typedef struct _vnet_feature_arc_registration { /** next registration in list of all registrations*/ struct _vnet_feature_arc_registration *next; /** Feature Arc name */ char *arc_name; /** Start nodes */ char **start_nodes; int n_start_nodes; /** End of the arc (optional, for consistency-checking) */ char *last_in_arc; /* Feature arc index, assigned by init function */ u8 feature_arc_index; u8 *arc_index_ptr; } vnet_feature_arc_registration_t; # VNET_FEATURE_ARC_INIT宏用来注册arc # ---------------------------------- # 在arc中指定的起始node中，必须调用vnet_feature_arc_start函数， # 才能正式进入feature机制业务流程，该函数会将下一跳强行指定为arc中的下一个feature # 先初始化arc VNET_FEATURE_ARC_INIT (device_input, static) = { .</description>
    </item>
    
    <item>
      <title>WCG-deps-install</title>
      <link>https://workerwork.github.io/posts/wcg-deps/</link>
      <pubDate>Tue, 28 Apr 2020 09:45:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/wcg-deps/</guid>
      <description>1. 下载对应的依赖包 # yumdownloader --downloadonly --downloaddir=. xxx # 提取包内容 # rpm2cpio *.rpm | cpio -div  2. install.sh #!/bin/bash - ########################################################## # wcg-deps-install.sh # version:1.0 # update:20181120 ########################################################## DIR=&amp;quot;/home/wcg/WCG-deps&amp;quot; function wcg_deps() { for dir in curl fcgi gsoap lksctp lrzsz vconfig tftp redis spawn-fcgi keepalived openssh nginx net-tools libevent do cd $DIR/$dir &amp;amp;&amp;amp; rpm -Uvh *.rpm --force --nodeps &amp;amp; done } function segw_deps() { for dir in segw do cd $DIR/$dir &amp;amp;&amp;amp; rpm -Uvh *.</description>
    </item>
    
    <item>
      <title>kernel 字符设备驱动</title>
      <link>https://workerwork.github.io/posts/kernel-dev/</link>
      <pubDate>Wed, 22 Apr 2020 15:14:50 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/kernel-dev/</guid>
      <description>1. 字符设备 Linux字符设备是一种按字节来访问的设备，字符驱动则负责驱动字符设备，这样的驱动通常实现open、close、read和write系统调用。例如：串口、Led、按键等
通过字符设备文件（/dev/xxx），应用程序可以使用相应的字符设备驱动来控制字符设备
2. 如何创建字符设备  使用命令mknod : mknod /dev/文件名 c 主设备号 次设备号 （查看主设备号：cat /proc/devices） 使用函数创建：mknod()
int mknod(const char *pathname, mode_t mode, dev_t dev);   3. 文件系统与字符设备驱动程序之间的关系  在Linux系统中，每一个打开的文件，在内核中都会关联一个struct file结构，它是由内核在打开文件时创建，在文件关闭后释放。
struct file结构中的重要成员 * struct file_operations* f_op;　//文件操作函数集 * loff_t f_pos;　//文件读写指针  每一个存在于文件系统中的文件都会关联一个inode结构，该结构主要用来记录文件物理上的信息。因此，它和代表打开文件的file结构是不同的，一个文件没有被打开时不会关联file结构，但是会关联一个inode结构（存于磁盘，操作文件时在内存中建立相应的映射结构）
  注：inode用于存储文件的元信息（除了文件名的所有信息），中文译名索引节点
 从上图可知，系统实质上是把字符设备的注册表看成了文件。其中chrdevs[]在内核的定义如下
static struct char_device_struct { struct char_device_struct *next; unsigned int major; unsigned int baseminor; int minorct; char name[64]; struct cdev *cdev; /* will die */ } *chrdevs[CHRDEV_MAJOR_HASH_SIZE];   4.</description>
    </item>
    
    <item>
      <title>cpu亲和性</title>
      <link>https://workerwork.github.io/posts/affinity/</link>
      <pubDate>Mon, 20 Apr 2020 16:17:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/affinity/</guid>
      <description>1. 什么是cpu亲和性(affinity) CPU的亲和性， 就是进程要在指定的 CPU 上尽量长时间地运行而不被迁移到其他处理器，也称为CPU关联性； 再简单的点的描述就将制定的进程或线程绑定到相应的cpu上； 在多核运行的机器上，每个CPU本身自己会有缓存，缓存着进程使用的信息，而进程可能会被OS调度到其他CPU上， 如此，CPU cache命中率就低了，当绑定CPU后，程序就会一直在指定的cpu跑，不会由操作系统调度到其他CPU上，性能有一定的提高。
软亲和性(affinity): 就是进程要在指定的CPU上尽量长时间地运行而不被迁移到其他处理器，Linux内核进程调度器天生就具有被称为软CPU亲和性(affinity) 的特性，这意味着进程通常不会在处理器之间频繁迁移。 这种状态正是我们希望的，因为进程迁移的频率小就意味着产生的负载小。
硬亲和性(affinity): 简单来说就是利用linux内核提供给用户的API，强行将进程或者线程绑定到某一个指定的cpu核运行。
解释: 在linux内核中，所有的进程都有一个相关的数据结构，称为 task_struct。这个结构非常重要，原因有很多；其中与 亲和性（affinity）相关度最高的是 cpus_allowed 位掩码。 这个位掩码由 n 位组成，与系统中的 n 个逻辑处理器一一对应。 具有 4 个物理 CPU 的系统可以有 4 位。如果这些 CPU 都启用了超线程，那么这个系统就有一个 8 位的位掩码。 如果为给定的进程设置了给定的位，那么这个进程就可以在相关的 CPU 上运行。因此，如果一个进程可以在任何 CPU 上运行，并且能够根据需要在处理器之间进行迁移，那么位掩码就全是 1。 实际上，这就是 Linux 中进程的缺省状态;（这部分内容在这个博客中有提到一点：http://www.cnblogs.com/wenqiang/p/4802619.html）
cpus_allowed用于控制进程可以在哪里处理器上运行
sched_set_affinity() （用来修改位掩码）
sched_get_affinity() （用来查看当前的位掩码）
2. 进程与cpu的绑定 sched_setaffinity可以将某个进程绑定到一个特定的CPU。你比操作系统更了解自己的程序，为了避免调度器愚蠢的调度你的程序，或是为了在多线程程序中避免缓存失效造成的开销，你可能会希望这样做
在进行进程与cpu的绑定前，我们先了解编写程序需要准备的知识点
SCHED_SETAFFINITY(2) Linux Programmer&#39;s Manual SCHED_SETAFFINITY(2) NAME sched_setaffinity, sched_getaffinity - set and get a process&#39;s CPU affinity mask SYNOPSIS #define _GNU_SOURCE /* See feature_test_macros(7) */ #include &amp;lt;sched.</description>
    </item>
    
    <item>
      <title>kernel module编程</title>
      <link>https://workerwork.github.io/posts/kernel-module/</link>
      <pubDate>Fri, 17 Apr 2020 10:33:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/kernel-module/</guid>
      <description>1. Linux Kernel Module是什么 Linux Kernel Module是一段可以在运行时被加载到Linux Kernel中的代码，可以使用Kernel Functions。Linux Kernel Module的用途很广，最常见的例子就是Device Driver，也就是设备驱动程序。
如果没有Linux Kernel Module，每一行修改Kernel代码，每一个新增的Kernel功能特性，都需要重新编译Kernel，大大浪费了时间和效率。
2. kernel module编程 [root@localhost test]# ll 总用量 16 -rw-r--r--. 1 root root 728 4月 17 10:28 hello.c -rw-r--r--. 1 root root 229 4月 17 10:24 Makefile -rw-r--r--. 1 root root 190 4月 17 10:26 mymax.c -rw-r--r--. 1 root root 70 4月 17 10:17 mymax.h  [root@localhost test]# cat hello.c #include &amp;lt;linux/init.h&amp;gt;	/* Needed for the module-macros */ #include &amp;lt;linux/module.</description>
    </item>
    
    <item>
      <title>kvm虚拟机</title>
      <link>https://workerwork.github.io/posts/kvm/</link>
      <pubDate>Wed, 15 Apr 2020 09:45:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/kvm/</guid>
      <description>1. 检查CPU是否支持kvm # egrep -q &amp;quot;(svm|vmx)&amp;quot; /proc/cpuinfo &amp;amp;&amp;amp; echo &amp;quot;yes!&amp;quot;  2. 配置yum源 # wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo　//基础源 # wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo　//epel源 # yum clean all　//清空yum缓存  3. 安装虚拟机管理工具和依赖 # yum -y install qemu-kvm //KVM主程序，KVM虚拟化模块 # yum -y install virt-install //安装虚拟机的工具 # 这个包主要安装了virt-install、virt-clone和virt-xml命令，分别用于安装虚拟机系统、克隆虚拟机和编辑虚拟机的xml配置文件。 # yum -y install virt-manager //KVM图形化管理工具 # yum -y install libvirt //虚拟化服务库 # libvirt是用于管理虚拟化平台的开源的API（libvirt API），后台程序（libvirtd进程）和管理工具（virsh工具集）。 # 它可以用于管理KVM、Xen、VMware ESX，QEMU和其他虚拟化技术。这些API在云计算的解决方案中广泛使用。 # libvirtd进程主要实现远程代理、本地环境初始化、根据环境注册各种Driver（qemu、xen、storage）的实现。 # virsh工具集主要用于管理、操作虚拟主机。 # yum -y install libguestfs-tools //虚拟机的系统管理工具 # libguestfs -tools是一组Linux下的C语言的API，用来访问虚拟机的磁盘映像文件。 # 该工具包内包含的工具有virt-cat、virt-df、virt-list、virt-copy-in、virt-copy-out、 # virt-edit、guestfs、guestmount、virt-list-filesystems、virt-list-partitions等工具。 # 该工具可以在不启动KVM guest主机的情况下，直接查看guest主机内的文内容，也可以直接向img镜像中写入文件和复制文件到外面的物理机， # 也可以将guest的镜像文件挂载，功能相当强大 # yum -y install libvirt-python //python调用libvirt虚拟化服务的api接口库文件  4.</description>
    </item>
    
    <item>
      <title>linux内核定制</title>
      <link>https://workerwork.github.io/posts/self-kernel/</link>
      <pubDate>Tue, 14 Apr 2020 16:20:00 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/self-kernel/</guid>
      <description>1. 下载内核源代码 从 http://www.kernel.org 下载内核源代码RPM包 例如linux-2.6.27.62.tar.bz2
2. 解压内核 # bzip2 -d linux-2.6.27.62.tar.bz2 # tar -xvf linux-2.6.27.62.tar  3. 定制内核 #定制内核有很多种方法：make config(最基本方法),make defconfig（默认的方法) # make config # make defconfig # make menuconfig #会生成.config文件，这个文件也可以从/boot路径下拷贝 #Y是该选项能够构建到内核内部 #M是构建模块  4. 构建内核 # make clean //这一步最好执行一下 # make -j2  5. 打包成rpm # make rpm  6. 安装并引导内核 # make modules_install //安装模块 # make install //安装内核 #这时，系统会自动在你的启动菜单中加入启动新内核的菜单,如 [root@localhost linux-2.6.27.62]# cat /boot/grub/menu.lst default=1 timeout=5 splashimage=(hd0,0)/grub/splash.xpm.gz hiddenmenu title Red Hat Enterprise Linux AS (2.</description>
    </item>
    
    <item>
      <title>WCG内核修改</title>
      <link>https://workerwork.github.io/posts/wcg-kernel/</link>
      <pubDate>Tue, 14 Apr 2020 09:40:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/wcg-kernel/</guid>
      <description>1. 下载源代码包 从 http://vault.centos.org 下载内核源代码RPM包
2. 安装源代码包 [root@wcg-9-73 df]# rpm -ivh kernel-3.10.0-1062.el7.src.rpm  执行命令后会生成/root/rpmbuild路径,包含SPECS和SOURCES
3. 修改源码 [root@wcg-9-73 df]# cd /root/rpmbuild/SOURCES [root@wcg-9-73 SOURCES]# xz -d linux-3.10.0-1062.el7.tar.xz [root@wcg-9-73 SOURCES]# tar -xvf linux-3.10.0-1062.el7.tar #将修改后的代码替换 [root@wcg-9-73 SOURCES]# cd linux-3.10.0-1062.el7/ [root@wcg-9-73 linux-3.10.0-1062.el]# cd net/ipv4/ [root@wcg-9-73 ipv4]# rm -rf udp.c &amp;amp;&amp;amp; cp -rf /root/df/udp.c . [root@wcg-9-73 ipv4]# cd ../../include/uapi/linux/ [root@wcg-9-73 linux]# rm -rf udp.h &amp;amp;&amp;amp; cp -rf /root/df/udp.h . [root@wcg-9-73 linux]# cd ../../../ [root@wcg-9-73 SOURCES]# tar -cvf linux-3.</description>
    </item>
    
    <item>
      <title>Build 5GC-C</title>
      <link>https://workerwork.github.io/posts/5gc-c-build/</link>
      <pubDate>Wed, 01 Apr 2020 15:57:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/5gc-c-build/</guid>
      <description>1. 安装打包工具 apt-get install -y build-essential apt-get install -y ruby rubygems ruby-dev #gem sources --add https://gems.ruby-china.org/ --remove https://rubygems.org/ #gem sources -l gem install fpm  2. 构建目录结构  tree文件
root@gmzhang-dev:/home/gmzhang/work/dongfeng/deb-build/5gc-c-build# tree . ├── build.sh ├── README.md └── source ├── 5gc-c.service ├── amf │ └── amf1 │ ├── bin │ │ └── amf │ ├── config │ │ ├── amf.conf │ │ └── asn.log.properties │ ├── context │ │ └── SystemVersionDB │ ├── data │ │ └── statistics │ ├── licensefile -&amp;gt; .</description>
    </item>
    
    <item>
      <title>创建ubuntu docker镜像</title>
      <link>https://workerwork.github.io/posts/ubuntu-docker/</link>
      <pubDate>Tue, 24 Mar 2020 15:48:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/ubuntu-docker/</guid>
      <description>1. 创建Dockerfile [dongfeng@localhost test]$ cat Dockerfile FROM ubuntu:18.04 MAINTAINER The UbuntuOS Project &amp;lt;dongfeng@baicells.com&amp;gt; ENV container docker ENV LC_ALL C ENV DEBIAN_FRONTEND noninteractive RUN sed -i &#39;s/# deb/deb/g&#39; /etc/apt/sources.list RUN apt-get update -yqq \ &amp;amp;&amp;amp; apt-get install -yq apt-utils \ &amp;amp;&amp;amp; apt-get install -yq curl \ &amp;amp;&amp;amp; apt-get install -yq git \ &amp;amp;&amp;amp; apt-get install -yq unzip zip tar \ &amp;amp;&amp;amp; apt-get install -yq ca-certificates \ &amp;amp;&amp;amp; apt-get install -yq bash-completion \ &amp;amp;&amp;amp; apt-get install -yq iproute2 iputils-ping \ &amp;amp;&amp;amp; apt-get install -yq systemd systemd-sysv \ &amp;amp;&amp;amp; apt-get clean \ &amp;amp;&amp;amp; apt-get autoclean \ &amp;amp;&amp;amp; apt-get autoremove \ &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* RUN cd /lib/systemd/system/sysinit.</description>
    </item>
    
    <item>
      <title>something</title>
      <link>https://workerwork.github.io/books/</link>
      <pubDate>Tue, 24 Mar 2020 10:02:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/books/</guid>
      <description>docker kubernetes openstack openshift starlingx SDN NFV VPP OVS ONOS cord DPDK vagrant kvm vmware virtualbox docker-compose ansible debootstrap febootstrap devops CI/CD python c golang rust shell gotty vtysh git gogs gitlab gitbook redis nginx tomcat caddy keepalived mysql ipsec hugo html css js chrome plugin vpncity nordvpn ghelper swagger shc tmux 看板娘 tor pyinstaller ripgrep fpm 蜜罐 蜜网 testlink 本地yum仓库 本地docker仓库 本地网盘 本地dns jenkins drone rancher 免流 remmina远程 notebook 锐速bbr TIG(telegraf influxdb grafana) 暗网 渗透测试 社工钓鱼 busybox rpm打包 guake 内网穿透 code-server helm 简书 yaml toml markdown gRPC REST KV数据库 cgo RISC-v ARM X86 KubeSpray ceph PXE批量安装系统 磁盘阵列 doxygen git review epoll UDEV UIO VFIO ltrace rpmreaper repoquery &amp;ndash;requires &amp;ndash;resolve openssh minicom shell dialog whiptail ovirt 云桌面 kolla-ansible 部署openstack Travis CI aptitude p4 rufus 安装盘制作工具 OpenDataPlane OpenFastPath make &amp;amp;&amp;amp; makefile LAMP + 视频服务器docker镜像 phpmyadmin ubuntu编译环境build-essential dmidecode获取系统硬件信息 cmake &amp;amp;&amp;amp; ccmake alien deb&amp;lt;-&amp;gt;rpm MongoDB 非关系型数据库 locals() python动态变量 microbit flock &amp;amp;&amp;amp; exec xrdp远程桌面服务 shell一些用法 :&amp;gt;file #清空文件 :&amp;lt;&amp;lt;BLOCK #注释 some document.</description>
    </item>
    
    <item>
      <title>创建ubuntu基础镜像</title>
      <link>https://workerwork.github.io/posts/debootstrap/</link>
      <pubDate>Mon, 23 Mar 2020 22:09:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/debootstrap/</guid>
      <description>1. 安装debootstrap ubuntu操作系统：apt install debootstrap centos操作系统：yum install debootstrap  2. 构建基础Ubuntu的rootfs mkdir /mnt/rootfs debootstrap --verbose --arch=amd64 bionic /mnt/rootfs http://mirrors.aliyun.com/ubuntu 说明：bionic为ubuntu代号，/mnt/rootfs为存放rootfs目录  3. 配置rootfs #切换根 chroot . #安装依赖包 apt-get -y update apt-get -y upgrade apt-get -y install vim locales iproute2 gzip curl sudo tar zip unzip telnet openssl gcc make openssh-server openssh-client #创建用户 useradd -m dongfeng echo &amp;quot;root:baicells&amp;quot; | chpasswd echo &amp;quot;dongfeng:baicells&amp;quot; | chpasswd #配置sshd mkdir /run/sshd mkdir /var/run/sshd sshd -D echo UseDNS no &amp;gt;&amp;gt; /etc/ssh/sshd_config #其他配置 cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime dpkg-reconfigure locales rm -Rf /tmp/* &amp;amp;&amp;amp; apt clean #清理系统 rm -rf boot/ dev/ media/ mnt/ proc/ srv/ sys/echo &amp;gt; root/.</description>
    </item>
    
    <item>
      <title>ubuntu搭建gitlab服务器</title>
      <link>https://workerwork.github.io/posts/gitlab/</link>
      <pubDate>Sat, 21 Mar 2020 12:27:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/gitlab/</guid>
      <description>1. 安装docker替换国内镜像源 #卸载之前的docker版本 sudo apt-get remove docker docker-engine docker-ce docker.io #apt元数据更新 sudo apt-get update #安装以下包，以使apt可以通过https来使用repository sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common #添加docker官方GPG秘钥并更新元数据 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo apt-get update #添加docker仓库 sudo add-apt-repository &amp;quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&amp;quot; sudo apt-get update #列出docker可用版本，选择一个安装 sudo apt-cache madison docker-ce sudo apt-get install docker-ce= #替换docker镜像源 sudo vim /etc/docker/daemon.json，添加 { &amp;quot;registry-mirrors&amp;quot;: [&amp;quot;https://9w1hl6qt.mirror.aliyuncs.com&amp;quot;] }  2. 安装docker-compose yum -y install epel-release yum -y install python-pip pip install --upgrade pip pip install docker-compose #或者二进制安装 curl -L https://github.</description>
    </item>
    
    <item>
      <title>基于VPP&#43;DPDK开源框架开发UPF</title>
      <link>https://workerwork.github.io/posts/vpp/</link>
      <pubDate>Fri, 01 Nov 2019 16:11:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/vpp/</guid>
      <description>DPDK DPDK是什么 DPDK全称为Date plane development kit，是一个用来进行包数据处理加速的软件库。
为什么DPDK 传统 Linux 内核网络数据流程：
硬件中断---&amp;gt;取包分发至内核线程---&amp;gt;软件中断---&amp;gt;内核线程在协议栈中处理包---&amp;gt;处理完毕通知用户层 用户层收包--&amp;gt;网络层---&amp;gt;逻辑层---&amp;gt;业务层  基于传统 OS 内核的数据处理的弊端：
 中断处理。当网络中大量数据包到来时，会产生频繁的硬件中断请求，这些硬件中断可以打断之前较低优先级的软中断或者系统调用的执行过程，如果这种打断频繁的话，将会产生较高的性能开销。
 内存拷贝。正常情况下，一个网络数据包从网卡到应用程序需要经过如下的过程：数据从网卡通过 DMA 等方式传到内核开辟的缓冲区，然后从内核空间拷贝到用户态空间，在 Linux 内核协议栈中，这个耗时操作甚至占到了数据包整个处理流程的 57.1%。
 上下文切换。频繁到达的硬件中断和软中断都可能随时抢占系统调用的运行，这会产生大量的上下文切换开销。另外，在基于多线程的服务器设计框架中，线程间的调度也会产生频繁的上下文切换开销，同样，锁竞争的耗能也是一个非常严重的问题。
 局部性失效。如今主流的处理器都是多个核心的，这意味着一个数据包的处理可能跨多个 CPU 核心，比如一个数据包可能中断在 cpu0，内核态处理在 cpu1，用户态处理在 cpu2，这样跨多个核心，容易造成 CPU 缓存失效，造成局部性失效。如果是 NUMA 架构，更会造成跨 NUMA 访问内存，性能受到很大影响。
 内存管理。传统服务器内存页为 4K，为了提高内存的访问速度，避免 cache miss，可以增加 cache 中映射表的条目，但这又会影响 CPU 的检索效率。
  如何改进：
 控制层和数据层分离。将数据包处理、内存管理、处理器调度等任务转移到用户空间去完成，而内核仅仅负责部分控制指令的处理。这样就不存在上述所说的系统中断、上下文切换、系统调用、系统调度等等问题。
 使用多核编程技术代替多线程技术，并设置 CPU 的亲和性，将线程和 CPU 核进行一比一绑定，减少彼此之间调度切换。
 针对 NUMA 系统，尽量使 CPU 核使用所在 NUMA 节点的内存，避免跨内存访问。
 使用大页内存代替普通的内存，减少 cache-miss。</description>
    </item>
    
    <item>
      <title>关于我</title>
      <link>https://workerwork.github.io/about/</link>
      <pubDate>Fri, 30 Aug 2019 14:50:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/about/</guid>
      <description>宇宙蜉蝣，银河系和平使者，地球超人，中国好男人，北漂浪人，死宅
邮箱地址: workerwork@qq.com
github地址：https://github.com/workerwork
简书地址：https://www.jianshu.com/u/e1b9a125f88b</description>
    </item>
    
    <item>
      <title>CentOS7系统优化</title>
      <link>https://workerwork.github.io/posts/centos-good/</link>
      <pubDate>Fri, 30 Aug 2019 14:03:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/centos-good/</guid>
      <description>1. 修改ip地址、网关、主机名、DNS等 [root@localhost ~]# vi /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=eth0 #网卡名字 BOOTPROTO=static #静态IP地址获取状态 如：DHCP表示自动获取IP地址 IPADDR=192.168.1.113 #IP地址 NETMASK=255.255.255.0 #子网掩码 ONBOOT=yes#引导时是否激活 GATEWAY=192.168.1.1 [root@localhost ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=eth0 BOOTPROTO=static IPADDR=192.168.1.113 NETMASK=255.255.255.0 ONBOOT=yes GATEWAY=192.168.1.1 [root@localhost ~]# vi /etc/sysconfig/network HOSTNAME=c64 #修改主机名，重启生效 GATEWAY=192.168.1.1 #修改默认网关,如果上面eth0里面不配置网关的话，默认就使用这里的网关了。 [root@localhost ~]# cat /etc/sysconfig/network HOSTNAME=c64 GATEWAY=192.168.1.1 我们也可以用 hostnamec64 来临时修改主机名，重新登录生效 修改DNS [root@localhost ~]# vi /etc/resolv.conf #修改DNS信息 nameserver 114.114.114.114 nameserver 8.8.8.8 [root@localhost ~]# cat /etc/resolv.conf #查看修改后的DNS信息 nameserver 114.114.114.114 nameserver 8.8.8.8 [root@localhost ~]# systemctl restart network #重启网卡，生效  2.</description>
    </item>
    
    <item>
      <title>CentOS7安全加固</title>
      <link>https://workerwork.github.io/posts/security/</link>
      <pubDate>Fri, 30 Aug 2019 11:01:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/security/</guid>
      <description>1. 账号和口令 1 ）禁用或删除无用账号 减少系统无用账号，降低安全风险
#删除不必要的账号 userdel &amp;lt;用户名&amp;gt; #锁定不必要的账号 passwd -l &amp;lt;用户名&amp;gt; #解锁必要的账号 passwd -u &amp;lt;用户名&amp;gt;  2 ）检查特殊账号 检查是否存在空口令和root权限的账号
#查看空口令账号 awk -F: &#39;($2==&amp;quot;&amp;quot;)&#39; /etc/shadow #为空口令账号设定密码 passwd &amp;lt;用户名&amp;gt; #查看UID为零的账号，确认只有root账号 awk -F: &#39;($3==0)&#39; /etc/passwd  3 ）添加口令策略 加强口令的复杂度，降低被猜解的可能性
vi /etc/login.defs 修改配置文件 PASS_MAX_DAYS 90 #新建用户的密码最长使用天数 PASS_MIN_DAYS 0 #新建用户的密码最短使用天数 PASS_WARN_AGE 7 #新建用户的密码到期提前提醒天数 #或者使用chage命令修改用户设置 #将此用户的密码最长使用天数设为30，最短使用天数设为0，密码2000年1月1日过期，过期前七天警告用户 chage -m 0 -M 30 -E 2000-01-01 -W 7 &amp;lt;用户名&amp;gt; #设置连续输错三次密码，账号锁定五分钟 vi /etc/pam.d/common-auth 修改配置文件，添加 auth required pam_tally.so onerr=fail deny=3 unlock_time=300  4 ）限制用户su 限制能su到root的用户</description>
    </item>
    
    <item>
      <title>EPC的CI/CD</title>
      <link>https://workerwork.github.io/posts/epc-cicd/</link>
      <pubDate>Thu, 29 Aug 2019 14:17:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/epc-cicd/</guid>
      <description>1. 流程介绍 开发人员合并代码到gogs，触发钩子，drone根据git仓库中的.drone.yml进行工作，使用fpm进行rpm打包并更新本地yum仓库
2. .drone.yml workspace: base: /root/gogs path: epc-c pipeline: build: image: centos7.5:dev environment: - SSH_ARGS=-p 22 -o StrictHostKeyChecking=no - SCP_ARGS=-P 22 -o StrictHostKeyChecking=no - TEST_SERVER=root@192.168.9.105 - RUN_PATH=/root/df/caddy/filebrowser/files/EPC-VERSION commands: - git_rev=$(git rev-parse HEAD| cut -c1-10) - git clone http://192.168.9.105:60080/dongfeng/pack-epc-c.git - cd pack-epc-c - ./pack-epc-c.sh - rpm_name=&amp;quot;baicells-epc-c-$(cat VERSION)-$(cat RELEASE).x86_64.rpm&amp;quot; - rpm_rename=$(echo $rpm_name| awk -F .rpm &#39;{print $1}&#39;) - rpm_newname=&amp;quot;$rpm_rename&amp;quot;_&amp;quot;$(date &#39;+%Y%m%d&#39;)&amp;quot;_&amp;quot;$git_rev&amp;quot;.rpm - eval $(ssh-agent -s) - ssh-add /root/.ssh/id_rsa - scp $SCP_ARGS $rpm_name &amp;quot;$TEST_SERVER&amp;quot;:&amp;quot;$RUN_PATH&amp;quot;/&amp;quot;$rpm_newname&amp;quot; - ssh &amp;quot;$TEST_SERVER&amp;quot; &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;lt;&amp;lt; eeooff - cd /root/df/caddy/yum.</description>
    </item>
    
    <item>
      <title>使用caddy搭建文件服务器</title>
      <link>https://workerwork.github.io/posts/caddy/</link>
      <pubDate>Thu, 29 Aug 2019 11:56:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/caddy/</guid>
      <description>1. caddy介绍 caddy官网：https://caddyserver.com/ 项目源码：https://github.com/caddyserver/caddy
2. 下载caddy 从官网下载caddy，下载时选择需要的插件
3. 创建工作路径 mkdir caddy-workspace cd caddy-workspace  4. 创建Caddyfile 192.168.9.105:8888 { gzip root filebrowser log access.log errors errors.log filebrowser / filebrowser/files { database /root/df/caddy/filebrowser/filebrowser.db	} } 192.168.9.105:9999 { gzip browse root yum.repo log access.log errors errors.log } 192.168.9.105:7777 { gzip browse root static log access.log errors errors.log } 192.168.9.105:80 { proxy / http://192.168.103.147:80 } 192.168.9.105:5566 { gzip root test }  5. 运行caddy caddy &amp;amp;  6.</description>
    </item>
    
    <item>
      <title>使用docker-compose搭建drone服务器</title>
      <link>https://workerwork.github.io/posts/drone/</link>
      <pubDate>Thu, 29 Aug 2019 11:22:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/drone/</guid>
      <description>1. docker-compose介绍 docker-compose文档：https://docs.docker.com/compose/
drone文档：https://docs.drone.io/
2. 安装docker-compose yum -y install epel-release yum -y install python-pip pip install --upgrade pip pip install docker-compose #安装补全工具 yum install bash-completion curl -L https://raw.githubusercontent.com/docker/compose/$(docker-compose version --short)/contrib/completion/bash/docker-compose &amp;gt; /etc/bash_completion.d/docker-compose  3. 建立工作路径 mkdir docker-workspace cd docker-workspace  4. 创建docker-compose.yaml version: &#39;2&#39; services: #gogs: #image: gogs/gogs:latest #ports: # - &amp;quot;10022:22&amp;quot; # - 3000:3000 #volumes: # - /vagrant/gogs-data:/data #restart: always #mysql: #image: mysql:latest #ports: # - 3306:3306 #volumes: # - /vagrant/mysql-data:/var/lib/mysql #restart: always #environment: # - MYSQL_ROOT_PASSWORD=baicells # - MYSQL_DATABASE=gogs drone-server: image: drone/drone:latest ports: - 8000:8000 - 9000:9000 volumes: - /var/lib/drone:/var/lib/drone restart: always environment: # 开启注册，此配置允许任何人自注册和登录系统 - DRONE_OPEN=true #直接配置172.</description>
    </item>
    
    <item>
      <title>搭建jenkins服务器</title>
      <link>https://workerwork.github.io/posts/jenkins/</link>
      <pubDate>Thu, 29 Aug 2019 10:08:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/jenkins/</guid>
      <description> 1. jenkins介绍 jenkins官网：https://jenkins.io/zh/
项目源码：https://github.com/jenkinsci/jenkins
2. docker安装jenkins 1 ）下载jenkins的docker镜像 docker pull jenkins  2 ）创建jenkins存储目录 mkdir /home/var/jenkins  3 ）cd进入/home/var/目录，设置jenkins文件夹的归属用户UID为1000 chown -R 1000:1000 jenkins/  4 ）使用jenkins镜像创建容器 docker run -itd -p 8080:8080 -p 50000:50000 --name jenkins --privileged=true -v /home/var/jenkins:/var/jenkins_home jenkins  5 ）使用 ip:8080执行图像界面安装 </description>
    </item>
    
    <item>
      <title>使用gogs搭建git服务器</title>
      <link>https://workerwork.github.io/posts/gogs/</link>
      <pubDate>Thu, 29 Aug 2019 09:37:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/gogs/</guid>
      <description> 1. gogs介绍 gogs官网：https://gogs.io/ 项目源码：https://github.com/gogs/gogs
2. docker安装gogs 1 ）下载gogs的docker镜像 docker pull gogs/gogs  2 ）创建gogs存储目录 mkdir -p /var/gogs  3 ）使用gogs镜像创建容器 docker run -d --name=gogs -p 10022:22 -p 10080:3000 -v /var/gogs:/data gogs/gogs  4 ）使用 ip:10080执行图像界面安装 </description>
    </item>
    
    <item>
      <title>制作CentOS ISO</title>
      <link>https://workerwork.github.io/posts/centos-iso/</link>
      <pubDate>Wed, 28 Aug 2019 16:37:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/centos-iso/</guid>
      <description>1. 复制光盘文件 1）挂载iso镜像 #创建目录用于挂载光盘 mkdir /root/centos7 #挂载iso镜像 mount -o loop CentOS-7.0-1406-x86_64-DVD.iso /root/centos7  2）复制光盘文件到编辑目录进行编辑 因为挂载上iso镜像是只读的，如果要编辑，需要将文件复制出来，再编辑。
#首先创建编辑目录： mkdir /root/centos7_iso #复制光盘文件： cp -rf /root/centos7/* /root/centos7_iso/ #diskinfo treeinfo文件需单独拷贝下： cp /root/centos7/.discinfo /root/centos7_iso/ cp /root/centos7/.treeinfo /root/centos7_iso/  2. 编辑ks.cfg文件 系统安装的时候，按照ks.cfg文件的内容进行安装，我们把ks.cfg文件放到isolinux目录下：
cd /root/centos7_iso/isolinux  vim ks-init.cfg #platform=x86, AMD64, or Intel EM64T #version=DEVEL # Install OS instead of upgrade install # Keyboard layouts keyboard &#39;us&#39; # Root password rootpw --iscrypted $1$JtB/A66X$GCT7X3FCJVAPGd3sEY0mx0 # System language lang en_US # System authorization information auth --useshadow --passalgo=sha512 # Use cdrom installation media cdrom # Use text mode install #text graphical # SELinux configuration selinux --disabled # Do not configure the X Window System skipx #firstboot --enable #ignoredisk --only-use=sda # Firewall configuration firewall --disabled # Network information network --bootproto=dhcp --device=eth0 --onboot=no network --hostname=localhost.</description>
    </item>
    
    <item>
      <title>搭建本地yum仓库</title>
      <link>https://workerwork.github.io/posts/local-yum/</link>
      <pubDate>Wed, 28 Aug 2019 15:00:21 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/local-yum/</guid>
      <description>1. 安装工具 yum install -y createrepo  2. 编辑 comps.xml &amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt; &amp;lt;!DOCTYPE comps PUBLIC &amp;quot;-//CentOS//DTD Comps info//EN&amp;quot; &amp;quot;comps.dtd&amp;quot;&amp;gt; &amp;lt;comps&amp;gt; &amp;lt;group&amp;gt; &amp;lt;id&amp;gt;epc&amp;lt;/id&amp;gt; &amp;lt;name&amp;gt;epc&amp;lt;/name&amp;gt; &amp;lt;name xml:lang=&amp;quot;en_GB&amp;quot;&amp;gt;epc&amp;lt;/name&amp;gt; &amp;lt;description&amp;gt;epc installation.&amp;lt;/description&amp;gt; &amp;lt;default&amp;gt;false&amp;lt;/default&amp;gt; &amp;lt;uservisible&amp;gt;false&amp;lt;/uservisible&amp;gt; &amp;lt;packagelist&amp;gt; &amp;lt;packagereq type=&amp;quot;mandatory&amp;quot;&amp;gt;baicells-epc-base&amp;lt;/packagereq&amp;gt; &amp;lt;packagereq type=&amp;quot;mandatory&amp;quot;&amp;gt;baicells-epc-ui&amp;lt;/packagereq&amp;gt; &amp;lt;packagereq type=&amp;quot;mandatory&amp;quot;&amp;gt;baicells-epc-ovs-rest&amp;lt;/packagereq&amp;gt; &amp;lt;packagereq type=&amp;quot;mandatory&amp;quot;&amp;gt;baicells-epc-ovsdb-agent&amp;lt;/packagereq&amp;gt; &amp;lt;packagereq type=&amp;quot;mandatory&amp;quot;&amp;gt;baicells-epc-signaltrace&amp;lt;/packagereq&amp;gt; &amp;lt;packagereq type=&amp;quot;mandatory&amp;quot;&amp;gt;baicells-epc-gwsc&amp;lt;/packagereq&amp;gt; &amp;lt;packagereq type=&amp;quot;mandatory&amp;quot;&amp;gt;baicells-epc-openapi&amp;lt;/packagereq&amp;gt; &amp;lt;/packagelist&amp;gt; &amp;lt;/group&amp;gt; &amp;lt;/comps&amp;gt;  3. 创建仓库 createrepo -g comps.xml . #精确分组 #createrepo . #createrepo --update  4. 拷贝rpm包到仓库 mkdir rpms cp *.rpm rpms/  5.</description>
    </item>
    
    <item>
      <title>使用hugo搭建WorkSpace</title>
      <link>https://workerwork.github.io/posts/workspace/</link>
      <pubDate>Wed, 28 Aug 2019 10:16:21 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/workspace/</guid>
      <description>1. 什么是hugo 引用一下Hugo官网的描述
 The world’s fastest framework for building websites.
 Hugo是一个非常受欢迎的、开源的静态网站生成工具，和Hexo类似。 它速度快，扩展性强.
更多的关于Hugo的介绍，请参考Hugo的官网 https://gohugo.io/ .
2. 安装 hugo 从Github Release页面下载对应的二进制文件,然后把它放在你的PATH目录里即可使用。支持任何平台，根据自己的平台选择相应的二进制包即可。 github链接：https://github.com/gohugoio/hugo
#加入环境变量和执行权限 cp hugo /usr/bin/hugo chmod +x /usr/bin/hugo  3. 使用hugo创建站点 hugo new site workerwork.github.io-site  github链接：https://github.com/workerwork/workerwork.github.io-site
4. 给站点添加主题 cd workerwork.github.io-site git init git submodule add https://github.com/rujews/maupassant-hugo themes/maupassant # Edit your config.toml configuration file # and add the maupassant theme. echo &#39;theme = &amp;quot;maupassant&amp;quot;&#39; &amp;gt;&amp;gt; config.toml  5.</description>
    </item>
    
    <item>
      <title>部署kubernetes</title>
      <link>https://workerwork.github.io/posts/kubernetes-deploy/</link>
      <pubDate>Wed, 28 Aug 2019 10:16:21 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/kubernetes-deploy/</guid>
      <description>kubernetes Kubernetes官方提供三种部署方式： minikube minikube可以实现一种轻量级的Kubernetes集群，通过在本地计算机上创建虚拟机并部署只包含单个节点的简单集群。Minikube适用于Linux，MacOS和Windows系统。Minikube CLI提供集群管理的基本操作，包括 start、stop、status和delete
kubeadm kubeadm是Kubernetes1.6开始官方推出的快速部署Kubernetes集群工具，其思路是将Kubernetes相关服务容器化(Kubernetes静态Pod)以简化部署
custom solutions 最完整的方式，从零开始二进制搭建

部署步骤 准备环境 # 关闭防火墙： # systemctl stop firewalld # systemctl disable firewalld # 关闭selinux： # sed -i &#39;s/enforcing/disabled/&#39; /etc/selinux/config # setenforce 0 # 关闭swap： # swapoff -a # 临时 # vim /etc/fstab # 永久 # vim /etc/sysctl.conf: net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-arptables = 1 # 设置主机名： # hostnamectl set-hostname master # 修改/etc/hosts文件: # cat /etc/hosts 127.</description>
    </item>
    
    <item>
      <title>AUTO-EPC</title>
      <link>https://workerwork.github.io/posts/auto-epc/</link>
      <pubDate>Wed, 20 Feb 2019 16:46:44 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/auto-epc/</guid>
      <description>AUTO-EPC 使用方法 1 安装本地yum源 在ssh终端任意路径下，使用root用户执行
wget http://192.168.9.105:60080/dongfeng/local-yum/raw/master/install-local-repo.sh | sh  2 软件安装和升级 2.1 一般版本安装和升级 如果是初始安装,执行
yum install [rpm包名]  如果是升级，执行
yum update [rpm包名]  2.2 特定版本安装和升级 在本地文件共享服务器http://192.168.9.105:8888/files/EPC-VERSION/ 中存有历史版本文件，取出升级即可
EPC安装包含的RPM包  baicells-epc-ui-3.4.3-1.x86_64_20190220_8799690909.rpm baicells-epc-signaltrace-1.0.0-2.x86_64_20190219_aa985a04ab.rpm baicells-epc-ovsdb-agent-1.0.1-1.x86_64_20190219_e3f0eca7eb.rpm baicells-epc-ovs-rest-1.0.0-2.x86_64_20190219_0c410e6e7d.rpm baicells-epc-openapi-2.0.0-1.x86_64_20190219_52edfb20ba.rpm baicells-epc-gwsc-1.0.0-2.x86_64_20190219_379c4f0e4b.rpm baicells-epc-base-2.0.0-1.x86_64_20190219_d0b3e89484.rpm baicells-epc-c-2.0.0-1.x86_64_20190219_d0b55fsf32.rpm baicells-epc-ovs-1.0.0-1.x86_64_20190219_d1333f1f34.rpm  EPC各组件代码仓库  base库 http://192.168.9.105:60080/dongfeng/epc-base ui库 http://192.168.9.105:60080/dongfeng/epc-ui onos库 http://192.168.9.105:60080/baicells/onos/src/softcn ovs-rest库 http://192.168.9.105:60080/baicells/ovs-rest ovsdb-config-agent库 http://192.168.9.105:60080/baicells/ovsdb-config-agent openapi库 http://192.168.9.105:60080/dongfeng/openapi signaltrace库 http://192.168.9.105:60080/dongfeng/signaltrace epc-c库 http://192.168.9.105:60080/dongfeng/epc-c ovs库 http://192.168.9.105:60080/dongfeng/ovs  RPM包构造方法  开发在git代码托管服务器http://192.168.9.105:60080 上提交更新代码 由web钩子触发后台drone自动使用fpm进行rpm打包 打包好的rpm包自动拷贝到文件共享服务器http://192.168.9.105:8888/files/EPC-VERSION/ 并自动更新本地yum仓库  RPM打包版本 版本说明 以baicells-epc-ui-3.</description>
    </item>
    
    <item>
      <title>Wcg Install</title>
      <link>https://workerwork.github.io/posts/wcg-install/</link>
      <pubDate>Mon, 21 Jan 2019 16:46:44 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/wcg-install/</guid>
      <description>1 前言 1.1 术语    英文缩写 英文全称 中文全称     eGW enterprise gateway 企业网关   OMC operation and maintenance center 操作管理中心    1.2 目的 本文档用来指导安装部署业务网关
2 安装指导 2.1 安装系统 系统版本要求：centos7.2
安装步骤： 1. 在服务器上插入U盘/光盘安装盘 2. 服务器启动进入bios，设置从U盘/光盘启动 3. 服务器进入安装引导界面，选择安装centos7.2 4. 磁盘分区： * boot 2G * swap 16G * 余下空间给&amp;rdquo;/&amp;rdquo; 5. 选择gnome典型安装
2.2 更换内核  进入内核包所在路径 执行yum install kernel-3.10.0-514.el7.centos.x86_64-eGW.rpm替换为eGW专用内核 如果是efi启动执行：grub2-mkconfig -o /boot/efi/EFI/centos/grub.cfg 执行reboot重启系统 系统启动成功后，uname -a确认当前系统内核版本是否成功升级到514  2.</description>
    </item>
    
    <item>
      <title>My First Post</title>
      <link>https://workerwork.github.io/posts/my-first-post/</link>
      <pubDate>Mon, 21 Jan 2019 15:37:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/my-first-post/</guid>
      <description>this is the first test for hugo!</description>
    </item>
    
    <item>
      <title>归档</title>
      <link>https://workerwork.github.io/archives/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://workerwork.github.io/archives/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>