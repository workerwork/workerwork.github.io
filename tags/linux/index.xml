<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>linux on WorkSpace</title>
    <link>https://workerwork.github.io/tags/linux/</link>
    <description>Recent content in linux on WorkSpace</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 30 Nov 2020 12:09:51 +0800</lastBuildDate>
    
	<atom:link href="https://workerwork.github.io/tags/linux/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Linux 内核符号表</title>
      <link>https://workerwork.github.io/posts/system-map/</link>
      <pubDate>Mon, 30 Nov 2020 12:09:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/system-map/</guid>
      <description>1. 什么是符号(symbols) 什么是Symbol?
其实就是kernel中的变量(VariableName)或函数名称(Function Name)
这样可以方便程序员在写程序时可以直接参照这一份Symbol的索引文件，找到所需要的kernel信息，
这一份Symbol的索引文件又称为kernel symbol table
2. 内核符号表(Kernel Symbol Table) 内核符号表，就是在内核的内部函数或变量中，可供外部引用的函数和变量的符号表.
其实就是一个索引文件，它存在的目的就是让外部软件可以知道kernel文件内部实际分配的位置.
编译内核时，System.map文件用于存放内核符号表信息
System.map文件位于/或者/boot、/usr/src/linux/下
3. kallsyms 内核启动时候创建,供oops时定位错误，文件大小总为0，包含当前内核导出的、可供使用的变量或者函数；它只是内核数据的简单表示形式.
/proc/kallsyms是一个在启动时由Linux kernel实时产生的文件，当系统有任何变更时，它就会马上做出修正
可以理解为动态的符号表
4. 符号类型 | 符号类型 | 名称 | 说明 | |-|-|-| | A | Absolute | 符号的值是绝对值，并且在进一步链接过程中不会被改变 | | B | BSS | 符号在未初始化数据区或区（section）中，即在BSS段中 | | C | Common | 符号是公共的。公共符号是未初始化的数据。在链接时，多个公共符号可能具有同一名称。如果该符号定义在其他地方，则公共符号被看作是未定义的引用 | | D | Data | 符号在已初始化数据区中 | | G | Global | 符号是在小对象已初始化数据区中的符号。某些目标文件的格式允许对小数据对象（例如一个全局整型变量）可进行更有效的访问 | | I | Inderect | 符号是对另一个符号的间接引用 | | N | Debugging | 符号是一个调试符号 | | R | Read only | 符号在一个只读数据区中 | | S | Small | 符号是小对象未初始化数据区中的符号 | | T | Text | 符号是代码区中的符号 | | U | Undefined | 符号是外部的，并且其值为0（未定义 | | - | Stabs | 符号是a.</description>
    </item>
    
    <item>
      <title>Linux 内核调试 kdump vmcore</title>
      <link>https://workerwork.github.io/posts/vmcore/</link>
      <pubDate>Wed, 28 Oct 2020 11:42:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/vmcore/</guid>
      <description>1. kdump介绍 linux内核发送崩溃时，kdump会生成一个内核转储文件vmcore。 可以通过分析vmcore分析出内核崩溃的原因.
crash是一个被广泛应用的内核奔溃转储文件分析工具.
使用crash调试内核转储文件，需要安装crash工具和内核调试工具kernel-debuginfo.
2. 安装kdump crash kexec-tools 一般在系统镜像文件中就有相对应的rpm包
3. 配置kdump vim /boot/grub/menu.lst： 设置 crashkernel=auto vim /etc/kdump.conf： path /var/crash （core文件产生的目录）  4. 启动kdump systemctl start kdump  5. 安装kernel-debuginfo 下载内核版本对应的文件 kernel-debuginfo-3.10.0-957.el7.x86_64.rpm kernel-debuginfo-common-x86_64-3.10.0-957.el7.x86_64.rpm  6. 分析vmcore abrt-cli list crash /usr/lib/debug/lib/modules/3.10.0-957.el7.x86_64/vmlinux vmcore crash&amp;gt; bt PID: 7473 TASK: ffff9027d874bf40 CPU: 0 COMMAND: &amp;quot;cat&amp;quot; #0 [ffff9026d0ea3638] machine_kexec at ffffffffbd060b2a #1 [ffff9026d0ea3698] __crash_kexec at ffffffffbd113402 #2 [ffff9026d0ea3768] crash_kexec at ffffffffbd1134f0 #3 [ffff9026d0ea3780] oops_end at ffffffffbd717778 #4 [ffff9026d0ea37a8] no_context at ffffffffbd706f98 #5 [ffff9026d0ea37f8] __bad_area_nosemaphore at ffffffffbd70702f #6 [ffff9026d0ea3848] bad_area_nosemaphore at ffffffffbd7071a0 #7 [ffff9026d0ea3858] __do_page_fault at ffffffffbd71a730 #8 [ffff9026d0ea38c0] do_page_fault at ffffffffbd71a925 #9 [ffff9026d0ea38f0] page_fault at ffffffffbd716768 [exception RIP: strcmp+32] RIP: ffffffffbd353d20 RSP: ffff9026d0ea39a0 RFLAGS: 00010202 RAX: 000000000000002f RBX: ffff90240da5a080 RCX: 0000000000000000 RDX: 0000000000000000 RSI: 0000000000000001 RDI: ffff9026cd27fc11 RBP: ffff9026d0ea39a0 R8: 00000000004b1de2 R9: ffff9026cd27fc10 R10: ffff90253fc01d00 R11: ffffc0428c349fc0 R12: 0000000000000001 R13: ffff9026cd27fc10 R14: 0000000000000001 R15: ffff9027c16f1580 ORIG_RAX: ffffffffffffffff CS: 0010 SS: 0018 #10 [ffff9026d0ea39a8] send_log at ffffffffc0c22fd5 [xx] #11 [ffff9026d0ea3ac0] user_file at ffffffffc0c0c571 [xx] #12 [ffff9026d0ea3f00] sys_open at ffffffffc0c56670 [xxt] #13 [ffff9026d0ea3f50] system_call_fastpath at ffffffffbd71f7d5 RIP: 00007f2e860c2a30 RSP: 00007fff6d8755a8 RFLAGS: 00010202 RAX: 0000000000000002 RBX: 00007fff6d875868 RCX: 000000000060bc60 RDX: 1fffffffffff0000 RSI: 0000000000000000 RDI: 00007fff6d876293 RBP: 0000000000001000 R8: 0000000000000000 R9: 0000000000000000 R10: 00007fff6d875020 R11: 0000000000000246 R12: 0000000000402644 R13: 0000000000010000 R14: 0000000000000000 R15: 0000000000000000 ORIG_RAX: 0000000000000002 CS: 0033 SS: 002b crash&amp;gt; dis -l ffffffffbd353d20 /usr/src/debug/kernel-3.</description>
    </item>
    
    <item>
      <title>vpp-cli命令行总结</title>
      <link>https://workerwork.github.io/posts/vpp-cli/</link>
      <pubDate>Thu, 17 Sep 2020 17:37:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/vpp-cli/</guid>
      <description>1. 介绍 vpp网络协议栈配备了一组调试命令。访问CLI（具有适当权限）的最简单方法是使用vppctl命令:
sudo vppctl &amp;lt;cli command&amp;gt;  CLI解析器匹配静态的关键字字符串后，调用动作执行函数。 你可以通过在代码源文件中搜索VLIB_CLI_COMMAND宏的来查找CLI命令的源代码.
2. 调试和Telnet CLI 使用unix交互式参数或启动配置选项启用调试CLI。 这会导致VPP不以守护进程的情况启动，并在运行它的终端上显示命令行界面.
使用cli-listen localhost:5002选项启用Telnet CLI，这将导致VPP侦听localhost地址端口5002上的TCP连接。 然后，Telnet客户端可以连接到此端口（例如，telnet localhost 5002）并将收到命令行提示符。
以下配置将启用这两种机制：
unix { interactive cli-listen localhost:5002 }  CLI以横幅图形（可以禁用）和命令行提示符提示CLI开始。对于VPP的发布版本，命令行提示符通常为“vpp”， 对于启用了调试功能的开发版本，命令行提示符为“DBGvpp＃”,可以通过unix cli-prompt设置命令行提示符， 并通过unix cli-no-banner来禁止横幅.
3. CLI特征  &amp;lt;-或-&amp;gt; 左右光标键，在命令行内移动光标。 Ctrl-左/右将向左或向右搜索下一个单词的开头。 Home / end将光标跳转到行的开头和结尾。 可以使用exit命令关闭CLI。 或者，空输入行上的^ D也将关闭会话。关闭调试会话也将关闭VPP  4. 命令行参数与配置文件 VPP网络协议栈可以在命令行或配置文件中提供配置参数。 您可以通过搜索VLIB_CONFIG_FUNCTION宏在源代码中找到命令行参数解析器的相关代码。 调用VLIB_CONFIG_FUNCTION（foo_config，“foo”）将使函数foo_config接收名为“foo”的参数块中给出的所有参数， 例如：“foo {arg1 arg2 arg3 &amp;hellip;}”
VPP应用程序必须能够找到自己的可执行映像。确保这一点最简单方法是通过给出其绝对路径来调用VPP应用程序;
例如：/usr/bin/vpp 。
在启动时，VPP应用程序通过解析自己的ELF段以生成初始化，配置和退出处理程序的列表
配置文件：
还可以在启动配置文件中提供命令行参数，配置文件的路径在命令行上提供给VPP应用程序。
配置文件的格式是一个简单的文本文件，其内容与命令行相同，但是能够使用换行符使内容更加易于阅读。 例如：
unix { nodaemon /var/log/vpp/vpp.log full-coredump cli-listen localhost:5002 } api-trace { on } dpdk { dev 0000:03:00.</description>
    </item>
    
    <item>
      <title>Shared Memory</title>
      <link>https://workerwork.github.io/posts/shm/</link>
      <pubDate>Fri, 21 Aug 2020 09:22:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/shm/</guid>
      <description>1. Shared Memory介绍 共享内存是System V版本的最后一个进程间通信方式。共享内存，顾名思义就是允许两个不相关的进程访问同一个逻辑内存， 共享内存是两个正在运行的进程之间共享和传递数据的一种非常有效的方式。不同进程之间共享的内存通常为同一段物理内存。 进程可以将同一段物理内存连接到他们自己的地址空间中，所有的进程都可以访问共享内存中的地址。 如果某个进程向共享内存写入数据，所做的改动将立即影响到可以访问同一段共享内存的任何其他进程.
特别提醒：共享内存并未提供同步机制，也就是说，在第一个进程结束对共享内存的写操作之前， 并无自动机制可以阻止第二个进程开始对它进行读取，所以我们通常需要用其他的机制来同步对共享内存的访问，例如信号量.
2. C语言demo程序 //comm.h #ifndef _COMM_H__ #define _COMM_H__ #include&amp;lt;stdio.h&amp;gt; #include&amp;lt;sys/types.h&amp;gt; #include&amp;lt;sys/ipc.h&amp;gt; #include&amp;lt;sys/shm.h&amp;gt; #define PATHNAME &amp;quot;.&amp;quot; #define PROJ_ID 0x6666 int CreateShm(int size); int DestroyShm(int shmid); int GetShm(int size); #endif  //comm.c #include&amp;quot;comm.h&amp;quot; static int CommShm(int size,int flags) { key_t key = ftok(PATHNAME,PROJ_ID); if(key &amp;lt; 0) { perror(&amp;quot;ftok&amp;quot;); return -1; } int shmid = 0; if((shmid = shmget(key,size,flags)) &amp;lt; 0) { perror(&amp;quot;shmget&amp;quot;); return -2; } return shmid; } int DestroyShm(int shmid) { if(shmctl(shmid,IPC_RMID,NULL) &amp;lt; 0) { perror(&amp;quot;shmctl&amp;quot;); return -1; } return 0; } int CreateShm(int size) { return CommShm(size,IPC_CREAT | IPC_EXCL | 0666); } int GetShm(int size) { return CommShm(size,IPC_CREAT); }  //client.</description>
    </item>
    
    <item>
      <title>Unix domain socket</title>
      <link>https://workerwork.github.io/posts/uds/</link>
      <pubDate>Wed, 19 Aug 2020 15:29:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/uds/</guid>
      <description>1. Unix domain socket介绍 Unix domain socket 又叫 IPC(inter-process communication 进程间通信) socket，用于实现同一主机上的进程间通信. socket 原本是为网络通讯设计的，但后来在 socket 的框架上发展出一种 IPC 机制，就是 UNIX domain socket. 虽然网络 socket 也可用于同一台主机的进程间通讯(通过 loopback 地址 127.0.0.1)，但是 UNIX domain socket 用于 IPC更有效率：不需要经过网络协议栈，不需要打包拆包、计算校验和、维护序号和应答等，只是将应用层数据从一个进程拷贝到另一个进程. 这是因为，IPC机制本质上是可靠的通讯，而网络协议是为不可靠的通讯设计的. UNIX domain socket 是全双工的，API 接口语义丰富，相比其它 IPC 机制有明显的优越性，目前已成为使用最广泛的 IPC 机制， 比如 X Window 服务器和 GUI 程序之间就是通过 UNIX domain socket 通讯的. Unix domain socket 是 POSIX 标准中的一个组件，所以不要被名字迷惑，linux 系统也是支持它的.
2. C语言demo程序 下面是一个非常简单的服务器端程序，它从客户端读字符，然后将每个字符转换为大写并回送给客户端
#include &amp;lt;stdlib.h&amp;gt; #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;stddef.h&amp;gt; #include &amp;lt;sys/socket.</description>
    </item>
    
    <item>
      <title>video server</title>
      <link>https://workerwork.github.io/posts/video-server/</link>
      <pubDate>Wed, 19 Aug 2020 13:13:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/video-server/</guid>
      <description>1. SRS介绍 SRS/3.0，OuXuli，是一个流媒体集群，支持RTMP/HLS/WebRTC/SRT/GB28181，高效、稳定、易用，简单而快乐。 101 SRS is a RTMP/HLS/WebRTC/SRT/GB28181 streaming cluster, high efficiency, stable and simple.
项目地址: https://github.com/ossrs/srs
2. 运行docker容器启动srs服务 sudo docker run -d -p 1935:1935 -p 1985:1985 -p 8080:8080 ossrs/srs:3  3. 使用ffmpeg推流 需要安装ffmpeg
./pushflow.sh cat pushflow.sh #!/bin/bash while : do sudo ffmpeg -re -i dog.mp4 -vcodec copy -acodec copy -f flv -y rtmp://192.168.1.7:1935/live/livestream sleep 1 done  4. 终端使用vlc播放器拉流 视频地址填写: rtmp://192.168.1.7:1935/live/livestream
5. 使用live555支持rtsp 需要添加网关以指定监听地址 可以使用ffmpeg来转换视频源格式
ffmpeg -i dance.mp4 -codec copy -bsf: h264_mp4toannexb -f h264 dance.</description>
    </item>
    
    <item>
      <title>openssh8.1 rpm build</title>
      <link>https://workerwork.github.io/posts/openssh/</link>
      <pubDate>Fri, 14 Aug 2020 15:36:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/openssh/</guid>
      <description>1. 创建工作路径 mkdir -p /root/rpmbuild/{SOURCES,SPECS} cp openssh-8.1p1.tar.gz /root/rpmbuild/SOURCES/  2. 下载源码包 wget https://openbsd.hk/pub/OpenBSD/OpenSSH/portable/openssh-8.1p1.tar.gz  3. 制作准备 yum install rpm-build zlib-devel openssl-devel gcc perl-devel pam-devel unzip tar -zxf openssh-8.1p1.tar.gz cp ./openssh-8.1p1/contrib/redhat/openssh.spec . sed -i -e &amp;quot;s/%define no_x11_askpass 0/%define no_x11_askpass 1/g&amp;quot; openssh.spec sed -i -e &amp;quot;s/%define no_gnome_askpass 0/%define no_gnome_askpass 1/g&amp;quot; openssh.spec  4. 制作rpm包 rpmbuild -ba openssh.spec 如果出现 错误：构建依赖失败： openssl-devel &amp;lt; 1.1 被 ?? 需要 解决方法： vi openssh.spec 注释掉 BuildRequires: openssl-devel &amp;lt; 1.</description>
    </item>
    
    <item>
      <title>自建kvm虚拟机</title>
      <link>https://workerwork.github.io/posts/kvm2/</link>
      <pubDate>Wed, 22 Jul 2020 10:35:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/kvm2/</guid>
      <description>1. 自定义虚拟机 egrep -q &amp;quot;(svm|vmx)&amp;quot; /proc/cpuinfo &amp;amp;&amp;amp; echo &amp;quot;yes&amp;quot; lsmod|grep kvm # centos yum install -y qemu-kvm #KVM主程序，KVM虚拟化模块 yum install -y libvirt #虚拟化服务库 yum install -y bridge-utils ln -s /usr/libexec/qemu-kvm /usr/bin/qemu-kvm # ubuntu apt install qemu qemu-kvm apt install libvirt-bin apt install bridge-utils ln -s /usr/bin/qemu-system-x86_64 /usr/bin/qemu-kvm systemctl start libvirtd systemctl enable libvirtd qemu-img create -f qcow2 vm_NGC.img 20G #创建磁盘镜像 qemu-kvm -name vm_NGC -m 4096 -cpu host -enable-kvm -smp 8 -hda vm_NGC.</description>
    </item>
    
    <item>
      <title>DPDK-Devbind</title>
      <link>https://workerwork.github.io/posts/dpdk-devbind/</link>
      <pubDate>Tue, 30 Jun 2020 17:18:27 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/dpdk-devbind/</guid>
      <description>dpdk-devbind.py #! /usr/bin/env python # SPDX-License-Identifier: BSD-3-Clause # Copyright(c) 2010-2014 Intel Corporation # import sys import os import getopt import subprocess from os.path import exists, abspath, dirname, basename # The PCI base class for all devices network_class = {&#39;Class&#39;: &#39;02&#39;, &#39;Vendor&#39;: None, &#39;Device&#39;: None, &#39;SVendor&#39;: None, &#39;SDevice&#39;: None} encryption_class = {&#39;Class&#39;: &#39;10&#39;, &#39;Vendor&#39;: None, &#39;Device&#39;: None, &#39;SVendor&#39;: None, &#39;SDevice&#39;: None} intel_processor_class = {&#39;Class&#39;: &#39;0b&#39;, &#39;Vendor&#39;: &#39;8086&#39;, &#39;Device&#39;: None, &#39;SVendor&#39;: None, &#39;SDevice&#39;: None} cavium_sso = {&#39;Class&#39;: &#39;08&#39;, &#39;Vendor&#39;: &#39;177d&#39;, &#39;Device&#39;: &#39;a04b,a04d&#39;, &#39;SVendor&#39;: None, &#39;SDevice&#39;: None} cavium_fpa = {&#39;Class&#39;: &#39;08&#39;, &#39;Vendor&#39;: &#39;177d&#39;, &#39;Device&#39;: &#39;a053&#39;, &#39;SVendor&#39;: None, &#39;SDevice&#39;: None} cavium_pkx = {&#39;Class&#39;: &#39;08&#39;, &#39;Vendor&#39;: &#39;177d&#39;, &#39;Device&#39;: &#39;a0dd,a049&#39;, &#39;SVendor&#39;: None, &#39;SDevice&#39;: None} cavium_tim = {&#39;Class&#39;: &#39;08&#39;, &#39;Vendor&#39;: &#39;177d&#39;, &#39;Device&#39;: &#39;a051&#39;, &#39;SVendor&#39;: None, &#39;SDevice&#39;: None} cavium_zip = {&#39;Class&#39;: &#39;12&#39;, &#39;Vendor&#39;: &#39;177d&#39;, &#39;Device&#39;: &#39;a037&#39;, &#39;SVendor&#39;: None, &#39;SDevice&#39;: None} avp_vnic = {&#39;Class&#39;: &#39;05&#39;, &#39;Vendor&#39;: &#39;1af4&#39;, &#39;Device&#39;: &#39;1110&#39;, &#39;SVendor&#39;: None, &#39;SDevice&#39;: None} network_devices = [network_class, cavium_pkx, avp_vnic] crypto_devices = [encryption_class, intel_processor_class] eventdev_devices = [cavium_sso, cavium_tim] mempool_devices = [cavium_fpa] compress_devices = [cavium_zip] # global dict ethernet devices present.</description>
    </item>
    
    <item>
      <title>keepalived应用</title>
      <link>https://workerwork.github.io/posts/keepalived/</link>
      <pubDate>Tue, 30 Jun 2020 14:23:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/keepalived/</guid>
      <description>1. 监控脚本 在Master节点和Slave节点 /etc/keepalived目录下添加check_nginx.sh 文件，用于检测Nginx的存活状况
#!/bin/bash #时间变量，用于记录日志 d=`date --date today +%Y%m%d_%H:%M:%S` #计算nginx进程数量 n=`ps -C nginx --no-heading|wc -l` #如果进程为0，则尝试启动nginx，并且再次检测nginx进程数量， #如果还为0，说明nginx无法启动，此时需要关闭keepalived if [ $n -eq &amp;quot;0&amp;quot; ]; then #如果挂掉了，就启动nginx #注意nginx.conf配置文件的位置 #尝试重新启动nginx /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf sleep 3 #睡眠3秒 n2=`ps -C nginx --no-heading|wc -l` if [ $n2 -eq &amp;quot;0&amp;quot; ]; then #把nginx宕机时间写入日志 echo &amp;quot;$d nginx down,keepalived will stop&amp;quot; &amp;gt;&amp;gt; /usr/local/nginx/logs/check_ng.log #启动失败，将keepalived服务杀死。将vip漂移到其它备份节点 service keepalived stop fi fi  授权: chmod 755 /etc/keepalived/check_nginx.sh
2. 非抢占模式 在Master 节点 /etc/keepalived目录下，配置keepalived.</description>
    </item>
    
    <item>
      <title>网卡命名</title>
      <link>https://workerwork.github.io/posts/eth-name/</link>
      <pubDate>Tue, 30 Jun 2020 10:25:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/eth-name/</guid>
      <description>1. 背景 服务器通常有多块网卡，有板载集成的，同时也有插在PCIe插槽的.
Linux系统的命名原来是eth0,eth1这样的形式，但是这个编号往往不一定准确对应网卡接口的物理顺序.
为解决这类问题，dell开发了biosdevname方案.
systemd v197版本中将dell的方案作了进一步的一般化拓展.
linux内核启动过程中，会默认给网卡以ethX方式随机命名，然后再通过systemd去rename成其他名称.
2. rename流程 step1 依据/usr/lib/udev/rules.d/60-net.rules， 查看是否有ifcfg-xx配置文件（路径在/etc/sysconfig/network-scripts/), 是否有定义了指定MAC地址的配置文件（ifcfg-xx ，xx必须和配置文件的内容DEVICE一致），如果有，则命名改网卡； step2 依据/usr/lib/udev/rules.d/71-biosdevname.rules，如果biosdevname使能了（安装了biosdevname这个包，且内核启动参数显式设置为1）， 且网卡没有在step1中定义，则按照biosdevname命名规则rename网卡；（注意，如果没有安装biosdevname这个包，就没有这个文件） step3, 依据/lib/udev/rules.d/75-net-description.rules，将udev工具会根据device属性将填写网卡的属性命名，可能一个网卡会有多个维度的名称; step4，udev 根据step3中的赋值，按照指定的scheme规则，去给在step1 step2中没有命名的网卡命名; 强调：这个step顺序是在我们没有自定义自己的rules的前提下，如果用户自定义了自己的rules，则用户自定义为优先级最高  3. 命令策略(scheme规则) 1.如果从BIOS中能够取到可用的，板载网卡的索引号，则使用这个索引号命名，例如: eno1，如不能则尝试2 2.如果从BIOS中能够取到可以用的，网卡所在的PCI-E热插拔插槽(注：pci槽位号)的索引号，则使用这个索引号命名，例如: ens1，如不能则尝试3 3.如果能拿到设备所连接的物理位置（PCI总线号+槽位号？）信息，则使用这个信息命名，例如:enp2s0，如不能则尝试4 4.传统的kernel命名方法，例如: eth0，这种命名方法的结果不可预知的，即可能第二块网卡对应eth0，第一块网卡对应eth1 5.使用网卡的MAC地址来命名，这个方法一般不使用 同一个网卡通常同时具有多个维度的名称，systemd在选取的时候，按照有先后次序，使用先命中的 顺序可以简单理解为(eno1-ens1-enp1) root@Bai5gc:/sys/class/net/eth1# udevadm info /sys/class/net/eth1 P: /devices/pci0000:00/0000:00:02.2/0000:03:00.0/net/eth1 E: DEVPATH=/devices/pci0000:00/0000:00:02.2/0000:03:00.0/net/eth1 E: ID_BUS=pci E: ID_MODEL_FROM_DATABASE=Ethernet Connection X552 10 GbE Backplane E: ID_MODEL_ID=0x15ab E: ID_NET_DRIVER=ixgbe E: ID_NET_LINK_FILE=/lib/systemd/network/99-default.link E: ID_NET_NAME_MAC=enxb4a9fca897e7 E: ID_NET_NAME_ONBOARD=eno3 E: ID_NET_NAME_PATH=enp3s0f0 E: ID_PATH=pci-0000:03:00.0 E: ID_PATH_TAG=pci-0000_03_00_0 E: ID_PCI_CLASS_FROM_DATABASE=Network controller E: ID_PCI_SUBCLASS_FROM_DATABASE=Ethernet controller E: ID_VENDOR_FROM_DATABASE=Intel Corporation E: ID_VENDOR_ID=0x8086 E: IFINDEX=3 E: INTERFACE=eth1 E: SUBSYSTEM=net E: SYSTEMD_ALIAS=/sys/subsystem/net/devices/eth1 E: TAGS=:systemd: E: USEC_INITIALIZED=5061037 E: net.</description>
    </item>
    
    <item>
      <title>ubuntu18.04使用xrdp远程桌面</title>
      <link>https://workerwork.github.io/posts/remote-desktop/</link>
      <pubDate>Thu, 11 Jun 2020 09:01:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/remote-desktop/</guid>
      <description>1. 执行下面的脚本安装 http://www.c-nergy.be/downloads/install-xrdp-3.0.zip
root@dongfeng-virtual-machine:/home/dongfeng# cat Install-xrdp-3.0.sh #!/bin/bash ##################################################################################################### # Script_Name : install-xrdp-3.0.sh # Description : Perform a custom installation of xrdp # on ubuntu 18.04 and later # Date : May 2019 # written by : Griffon # Web Site :http://www.c-nergy.be - http://www.c-nergy.be/blog # Version : 3.0 # History : 3.0 - Added support for Ubuntu 19.04 # - New code for Look&#39;n feel using xsessionrc method # - New code for enabling Sound Redirection - compiling from source # - Removed -g parameter # : 2.</description>
    </item>
    
    <item>
      <title>使用rust语言&#43;SDL2库写游戏</title>
      <link>https://workerwork.github.io/posts/rust-game/</link>
      <pubDate>Mon, 08 Jun 2020 15:57:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/rust-game/</guid>
      <description>1. 安装rust curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh  2. 设置rust国内源 #当前用户目录下 /linuxidc/.cargo/ 的.cargo 文件夹，进入.cargo 当前目录，在当前目下创建 config 文件 source.crates-io] registry = &amp;quot;https://github.com/rust-lang/crates.io-index&amp;quot; replace-with = &#39;ustc&#39; [source.ustc] registry = &amp;quot;git://mirrors.ustc.edu.cn/crates.io-index&amp;quot;  3. 安装SDL库 dnf install SDL2 dnf install SDL2-devel dnf install SDL2_image-devel dnf install SDL2_gfx-devel dnf install SDL2_mixer-devel dnf install SDL2_ttf-devel  4. 创建rust项目 cargo new testSDL cd testSDL 编辑cargo.toml，加入sdl2依赖 [dongfeng@localhost testSDL]$ cat Cargo.toml [package] name = &amp;quot;testsdl&amp;quot; version = &amp;quot;0.</description>
    </item>
    
    <item>
      <title>frp内网穿透</title>
      <link>https://workerwork.github.io/posts/frp/</link>
      <pubDate>Thu, 14 May 2020 13:41:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/frp/</guid>
      <description>1. 正常情况一个内网主机与外网服务器的交互 以访问google为例
假设我们的主机IP是192.168.0.10，路由器LAN IP为192.168.0.1，WAN IP为211.22.145.234（这是一个公网IP), google 服务器 IP 为74.125.204.101。 1.主机构建HTTP请求数据包，目标IP为74.125.204.101，目标端口是80/443，源IP为192.168.0.10，源端口随机生成，假定为5000 2.主机检查目标IP地址，发现不在一个网段，数据包丢给默认网关192.168.0.1 3.路由器LAN口收到数据包，构建NAT映射，随机生成端口，假定为5500,这样映射就是：5500-&amp;gt;192.168.0.10:5000． WIN口收到的数据包，如果目标端口是5500,则会转发给192.168.0.10的5000端口 4.路由器修改数据包的源端口为5500,源ＩＰ地址为211.22.145.234，使用WAN口将数据包发出去 5.google服务器收到请求，构建响应HTTP数据包，目标IP地址为211.22.145.234,目标端口是5500 6.路由器WAN口收到数据包，目标端口是5500,查询NAT表，发现对应的机器是192.168.0.10:5000， 所以修改目标IP为192.168.0.10，目标端口为5000，并通过LAN口发送给主机 7.主机收到数据包，完成一次通信  2. 内网穿透实现 测试服务器没有公网IP，想要让外网直接调用内网的服务，就需要用到内网穿透.
和使用路由器与外网交互类似，需要有一个第三方拥有公网IP的服务器进行路由的中转，代替路由器的角色.
由内网服务器主动请求公网服务器，建立一个长连接，这时公网服务器就可以随时随地的向内网服务器发送消息了
当使用浏览器想要访问内网服务时，先将请求发送到公网服务器上，公网服务器再通过之前建立的长连接将请求发送到内网服务器中。
从而实现在外网请求内网服务的需求
3. 公网服务器设置 # wget https://github.com/fatedier/frp/releases/download/v0.14.1/frp_0.14.1_linux_amd64.tar.gz # sudo tar zxf frp_0.14.1_linux_amd64.tar.gz # cd frp_0.14.1_linux_amd64/ # sudo vim frps.ini # [common] bind_port = 8989 # frp服务的端口 vhost_http_port = 8889 # frp的http服务的端口 # 启动服务 # ./frps -c frps.ini # 前台直接启动，测试看日志方便 # nohup ./frps -c ./frps.ini &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp; # 后台运行  4.</description>
    </item>
    
    <item>
      <title>p4实践环境</title>
      <link>https://workerwork.github.io/posts/p4/</link>
      <pubDate>Wed, 06 May 2020 18:00:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/p4/</guid>
      <description>1. 安装ubuntu16.04(18.04)并更新依赖 # sudo apt update # sudo apt-get install automake cmake libjudy-dev libpcap-dev libboost-dev \ libboost-test-dev libboost-program-options-dev libboost-system-dev \ libboost-filesystem-dev libboost-thread-dev libevent-dev libtool \ flex bison pkg-config g++ libssl-dev -y # sudo apt-get install cmake g++ git automake libtool libgc-dev bison flex libfl-dev \ libgmp-dev libboost-dev libboost-iostreams-dev libboost-graph-dev \ llvm pkg-config python python-scapy python-ipaddr python-ply tcpdump curl -y # sudo apt-get install libreadline6 libreadline6-dev python-pip python-scapy -y # sudo pip install psutil # sudo pip install crcmod  2.</description>
    </item>
    
    <item>
      <title>github加速</title>
      <link>https://workerwork.github.io/posts/github-fast/</link>
      <pubDate>Tue, 05 May 2020 16:17:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/github-fast/</guid>
      <description>1. 给git设置socks5/vmess代理 前提是开启代理服务，可以使用V2rayL: https://github.com/jiangxufeng/v2rayL 和 ghelper
使用 https 的时候，就是使用 https 协议复制仓库的时候
git config --global http.proxy &#39;socks5://127.0.0.1:1080&#39; git config --global https.proxy &#39;socks5://127.0.0.1:1080&#39; git config --global http.proxy &#39;vmess://127.0.0.1:1081&#39; git config --global https.proxy &#39;vmess://127.0.0.1:1081&#39;  也可以直接修改用户主目录下的 .gitconfig 文件
[http] proxy = socks5://127.0.0.1:1080 [https] proxy = socks5://127.0.0.1:1080 [http] proxy = vmess://127.0.0.1:1081 [https] proxy = vmess://127.0.0.1:1081  取消代理
git config --global --unset http.proxy git config --global --unset https.proxy  查看已有代理
git config --global -l  在使用 git 开头的路径时，也就是在使用 ssh 通道时</description>
    </item>
    
    <item>
      <title>vpp node-graph编排过程</title>
      <link>https://workerwork.github.io/posts/vpp-node-graph/</link>
      <pubDate>Thu, 30 Apr 2020 10:14:26 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/vpp-node-graph/</guid>
      <description>1. vpp node graph VPP处理报文时是沿着一个有向图进行处理的，每一个功能单元称之为节点(node)
2. 数据结构 静态数据结构 节点全局管理结构vlib_node_main_t
typedef struct { /* Public nodes. */ /* 节点指针数组，使用下标作为索引 */ vlib_node_t **nodes; /* Node index hashed by node name. */ /* 根据节点名字进行hash，可以根据节点名字进行hash表查找 * 只有main线程才会委会该hash表 */ uword *node_by_name; u32 flags; /* 该标志表示Runtime信息已经被初始化过了 */ #define VLIB_NODE_MAIN_RUNTIME_STARTED (1 &amp;lt;&amp;lt; 0) /* Nodes segregated by type for cache locality. Does not apply to nodes of type VLIB_NODE_TYPE_INTERNAL. */ vlib_node_runtime_t *nodes_by_type[VLIB_N_NODE_TYPE]; /* Node runtime indices for input nodes with pending interrupts.</description>
    </item>
    
    <item>
      <title>vpp 节点报文处理流程分析</title>
      <link>https://workerwork.github.io/posts/vpp-node-fw/</link>
      <pubDate>Wed, 29 Apr 2020 11:14:24 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/vpp-node-fw/</guid>
      <description>1. 以sample例子来分析vpp节点对报文的处理流程 vpp/src/examples/sample-plugin/sample $ll total 56 -rw-rw-r-- 1 ych ych 886 Apr 1 17:34 CMakeLists.txt -rw-rw-r-- 1 ych ych 17933 Apr 1 17:34 node.c -rw-rw-r-- 1 ych ych 712 Apr 1 17:34 sample_all_api_h.h -rw-rw-r-- 1 ych ych 1068 Apr 1 17:34 sample.api -rw-rw-r-- 1 ych ych 6569 Apr 1 17:34 sample.c -rw-rw-r-- 1 ych ych 1135 Apr 1 17:34 sample.h -rw-rw-r-- 1 ych ych 960 Apr 1 17:34 sample_msg_enum.h -rw-rw-r-- 1 ych ych 5512 Apr 1 17:34 sample_test.</description>
    </item>
    
    <item>
      <title>vpp sample plugin</title>
      <link>https://workerwork.github.io/posts/vpp-sample-plugin/</link>
      <pubDate>Tue, 28 Apr 2020 17:25:50 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/vpp-sample-plugin/</guid>
      <description>1. plugin_sample.c 在此文件中定义feature和cli
#include &amp;lt;vnet/plugin/plugin.h&amp;gt; #include &amp;lt;plugin_sample/plugin_sample.h&amp;gt; plugin_sample_main_t plugin_sample_main; //开关实现 int plugin_sample_enable_disable(u32 sw_if_index, //index int enable_disable)	//开关标识 { vnet_sw_interface_t *sw; int ret = 0; /* Utterly wrong? */ if (pool_is_free_index (plugin_sample_main.vnet_main-&amp;gt;interface_main.sw_interfaces, //vnet_main结构中的interface_main结构中的sw接口 sw_if_index)) //接口索引 return VNET_API_ERROR_INVALID_SW_IF_INDEX; /* Not a physical port? */ sw = vnet_get_sw_interface(plugin_sample_main.vnet_main,	//vnet_main结构 sw_if_index);	if (sw-&amp;gt;type != VNET_SW_INTERFACE_TYPE_HARDWARE) return VNET_API_ERROR_INVALID_SW_IF_INDEX; vnet_feature_enable_disable(&amp;quot;ip4-unicast&amp;quot;, //挂载节点 &amp;quot;plugin_sample&amp;quot;, sw_if_index, enable_disable, 0, 0); return ret; } static clib_error_t* plugin_sample_enable_disable_command_fn(vlib_main_t* vm,	//vlib_main结构 unformat_input_t *input, vlib_cli_command_t *cmd) { u32 sw_if_index = ~0;	//~0 取反= 1 int enable_disable = 1; while(unformat_check_input(input) !</description>
    </item>
    
    <item>
      <title>WCG-deps-install</title>
      <link>https://workerwork.github.io/posts/wcg-deps/</link>
      <pubDate>Tue, 28 Apr 2020 09:45:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/wcg-deps/</guid>
      <description>1. 下载对应的依赖包 # yumdownloader --downloadonly --downloaddir=. xxx # 提取包内容 # rpm2cpio *.rpm | cpio -div  2. install.sh #!/bin/bash - ########################################################## # wcg-deps-install.sh # version:1.0 # update:20181120 ########################################################## DIR=&amp;quot;/home/wcg/WCG-deps&amp;quot; function wcg_deps() { for dir in curl fcgi gsoap lksctp lrzsz vconfig tftp redis spawn-fcgi keepalived openssh nginx net-tools libevent do cd $DIR/$dir &amp;amp;&amp;amp; rpm -Uvh *.rpm --force --nodeps &amp;amp; done } function segw_deps() { for dir in segw do cd $DIR/$dir &amp;amp;&amp;amp; rpm -Uvh *.</description>
    </item>
    
    <item>
      <title>kernel 字符设备驱动</title>
      <link>https://workerwork.github.io/posts/kernel-dev/</link>
      <pubDate>Wed, 22 Apr 2020 15:14:50 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/kernel-dev/</guid>
      <description>1. 字符设备 Linux字符设备是一种按字节来访问的设备，字符驱动则负责驱动字符设备，这样的驱动通常实现open、close、read和write系统调用。例如：串口、Led、按键等
通过字符设备文件（/dev/xxx），应用程序可以使用相应的字符设备驱动来控制字符设备
2. 如何创建字符设备  使用命令mknod : mknod /dev/文件名 c 主设备号 次设备号 （查看主设备号：cat /proc/devices） 使用函数创建：mknod()
int mknod(const char *pathname, mode_t mode, dev_t dev);   3. 文件系统与字符设备驱动程序之间的关系  在Linux系统中，每一个打开的文件，在内核中都会关联一个struct file结构，它是由内核在打开文件时创建，在文件关闭后释放。
struct file结构中的重要成员 * struct file_operations* f_op;　//文件操作函数集 * loff_t f_pos;　//文件读写指针  每一个存在于文件系统中的文件都会关联一个inode结构，该结构主要用来记录文件物理上的信息。因此，它和代表打开文件的file结构是不同的，一个文件没有被打开时不会关联file结构，但是会关联一个inode结构（存于磁盘，操作文件时在内存中建立相应的映射结构）
  注：inode用于存储文件的元信息（除了文件名的所有信息），中文译名索引节点
 从上图可知，系统实质上是把字符设备的注册表看成了文件。其中chrdevs[]在内核的定义如下
static struct char_device_struct { struct char_device_struct *next; unsigned int major; unsigned int baseminor; int minorct; char name[64]; struct cdev *cdev; /* will die */ } *chrdevs[CHRDEV_MAJOR_HASH_SIZE];   4.</description>
    </item>
    
    <item>
      <title>cpu亲和性</title>
      <link>https://workerwork.github.io/posts/affinity/</link>
      <pubDate>Mon, 20 Apr 2020 16:17:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/affinity/</guid>
      <description>1. 什么是cpu亲和性(affinity) CPU的亲和性， 就是进程要在指定的 CPU 上尽量长时间地运行而不被迁移到其他处理器，也称为CPU关联性； 再简单的点的描述就将制定的进程或线程绑定到相应的cpu上； 在多核运行的机器上，每个CPU本身自己会有缓存，缓存着进程使用的信息，而进程可能会被OS调度到其他CPU上， 如此，CPU cache命中率就低了，当绑定CPU后，程序就会一直在指定的cpu跑，不会由操作系统调度到其他CPU上，性能有一定的提高。
软亲和性(affinity): 就是进程要在指定的CPU上尽量长时间地运行而不被迁移到其他处理器，Linux内核进程调度器天生就具有被称为软CPU亲和性(affinity) 的特性，这意味着进程通常不会在处理器之间频繁迁移。 这种状态正是我们希望的，因为进程迁移的频率小就意味着产生的负载小。
硬亲和性(affinity): 简单来说就是利用linux内核提供给用户的API，强行将进程或者线程绑定到某一个指定的cpu核运行。
解释: 在linux内核中，所有的进程都有一个相关的数据结构，称为 task_struct。这个结构非常重要，原因有很多；其中与 亲和性（affinity）相关度最高的是 cpus_allowed 位掩码。 这个位掩码由 n 位组成，与系统中的 n 个逻辑处理器一一对应。 具有 4 个物理 CPU 的系统可以有 4 位。如果这些 CPU 都启用了超线程，那么这个系统就有一个 8 位的位掩码。 如果为给定的进程设置了给定的位，那么这个进程就可以在相关的 CPU 上运行。因此，如果一个进程可以在任何 CPU 上运行，并且能够根据需要在处理器之间进行迁移，那么位掩码就全是 1。 实际上，这就是 Linux 中进程的缺省状态;（这部分内容在这个博客中有提到一点：http://www.cnblogs.com/wenqiang/p/4802619.html）
cpus_allowed用于控制进程可以在哪里处理器上运行
sched_set_affinity() （用来修改位掩码）
sched_get_affinity() （用来查看当前的位掩码）
2. 进程与cpu的绑定 sched_setaffinity可以将某个进程绑定到一个特定的CPU。你比操作系统更了解自己的程序，为了避免调度器愚蠢的调度你的程序，或是为了在多线程程序中避免缓存失效造成的开销，你可能会希望这样做
在进行进程与cpu的绑定前，我们先了解编写程序需要准备的知识点
SCHED_SETAFFINITY(2) Linux Programmer&#39;s Manual SCHED_SETAFFINITY(2) NAME sched_setaffinity, sched_getaffinity - set and get a process&#39;s CPU affinity mask SYNOPSIS #define _GNU_SOURCE /* See feature_test_macros(7) */ #include &amp;lt;sched.</description>
    </item>
    
    <item>
      <title>kernel module编程</title>
      <link>https://workerwork.github.io/posts/kernel-module/</link>
      <pubDate>Fri, 17 Apr 2020 10:33:52 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/kernel-module/</guid>
      <description>1. Linux Kernel Module是什么 Linux Kernel Module是一段可以在运行时被加载到Linux Kernel中的代码，可以使用Kernel Functions。Linux Kernel Module的用途很广，最常见的例子就是Device Driver，也就是设备驱动程序。
如果没有Linux Kernel Module，每一行修改Kernel代码，每一个新增的Kernel功能特性，都需要重新编译Kernel，大大浪费了时间和效率。
2. kernel module编程 [root@localhost test]# ll 总用量 16 -rw-r--r--. 1 root root 728 4月 17 10:28 hello.c -rw-r--r--. 1 root root 229 4月 17 10:24 Makefile -rw-r--r--. 1 root root 190 4月 17 10:26 mymax.c -rw-r--r--. 1 root root 70 4月 17 10:17 mymax.h  [root@localhost test]# cat hello.c #include &amp;lt;linux/init.h&amp;gt;	/* Needed for the module-macros */ #include &amp;lt;linux/module.</description>
    </item>
    
    <item>
      <title>linux内核定制</title>
      <link>https://workerwork.github.io/posts/self-kernel/</link>
      <pubDate>Tue, 14 Apr 2020 16:20:00 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/self-kernel/</guid>
      <description>1. 下载内核源代码 从 http://www.kernel.org 下载内核源代码RPM包 例如linux-2.6.27.62.tar.bz2
2. 解压内核 # bzip2 -d linux-2.6.27.62.tar.bz2 # tar -xvf linux-2.6.27.62.tar  3. 定制内核 #定制内核有很多种方法：make config(最基本方法),make defconfig（默认的方法) # make config # make defconfig # make menuconfig #会生成.config文件，这个文件也可以从/boot路径下拷贝 #Y是该选项能够构建到内核内部 #M是构建模块  4. 构建内核 # make clean //这一步最好执行一下 # make -j2  5. 打包成rpm # make rpm  6. 安装并引导内核 # make modules_install //安装模块 # make install //安装内核 #这时，系统会自动在你的启动菜单中加入启动新内核的菜单,如 [root@localhost linux-2.6.27.62]# cat /boot/grub/menu.lst default=1 timeout=5 splashimage=(hd0,0)/grub/splash.xpm.gz hiddenmenu title Red Hat Enterprise Linux AS (2.</description>
    </item>
    
    <item>
      <title>制作CentOS ISO</title>
      <link>https://workerwork.github.io/posts/centos-iso/</link>
      <pubDate>Wed, 28 Aug 2019 16:37:51 +0800</pubDate>
      
      <guid>https://workerwork.github.io/posts/centos-iso/</guid>
      <description>1. 复制光盘文件 1）挂载iso镜像 #创建目录用于挂载光盘 mkdir /root/centos7 #挂载iso镜像 mount -o loop CentOS-7.0-1406-x86_64-DVD.iso /root/centos7  2）复制光盘文件到编辑目录进行编辑 因为挂载上iso镜像是只读的，如果要编辑，需要将文件复制出来，再编辑。
#首先创建编辑目录： mkdir /root/centos7_iso #复制光盘文件： cp -rf /root/centos7/* /root/centos7_iso/ #diskinfo treeinfo文件需单独拷贝下： cp /root/centos7/.discinfo /root/centos7_iso/ cp /root/centos7/.treeinfo /root/centos7_iso/  2. 编辑ks.cfg文件 系统安装的时候，按照ks.cfg文件的内容进行安装，我们把ks.cfg文件放到isolinux目录下：
cd /root/centos7_iso/isolinux  vim ks-init.cfg #platform=x86, AMD64, or Intel EM64T #version=DEVEL # Install OS instead of upgrade install # Keyboard layouts keyboard &#39;us&#39; # Root password rootpw --iscrypted $1$JtB/A66X$GCT7X3FCJVAPGd3sEY0mx0 # System language lang en_US # System authorization information auth --useshadow --passalgo=sha512 # Use cdrom installation media cdrom # Use text mode install #text graphical # SELinux configuration selinux --disabled # Do not configure the X Window System skipx #firstboot --enable #ignoredisk --only-use=sda # Firewall configuration firewall --disabled # Network information network --bootproto=dhcp --device=eth0 --onboot=no network --hostname=localhost.</description>
    </item>
    
  </channel>
</rss>